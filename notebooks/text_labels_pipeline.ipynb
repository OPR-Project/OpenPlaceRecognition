{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline\n",
    "from opr.pipelines.place_recognition.text_labels import TextLabelsPlaceRecognitionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_by_id(labels: List[str], id: str):\n",
    "    frame = labels[id]\n",
    "    all_labels = [i[\"value\"][\"text\"] for i in frame[\"back_cam_anno\"] + frame[\"front_cam_anno\"]]\n",
    "    all_labels = sum(all_labels, [])\n",
    "    return all_labels\n",
    "\n",
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return dist_error, angle_error\n",
    "\n",
    "def compute_translation_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    gt_trans = gt_pose[:3, 3]\n",
    "    pred_trans = pred_pose[:3, 3]\n",
    "    error = np.linalg.norm(gt_trans - pred_trans)\n",
    "    return error\n",
    "\n",
    "def compute_rotation_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    gt_rot = Rotation.from_matrix(gt_pose[:3, :3])\n",
    "    pred_rot = Rotation.from_matrix(pred_pose[:3, :3])\n",
    "    error = Rotation.inv(gt_rot) * pred_rot\n",
    "    error = error.as_euler('xyz', degrees=True)\n",
    "    error = np.linalg.norm(error)\n",
    "    return error\n",
    "\n",
    "def compute_absolute_pose_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    rotation_error = compute_rotation_error(gt_pose, pred_pose)\n",
    "    translation_error = compute_translation_error(gt_pose, pred_pose)\n",
    "    return rotation_error, translation_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights download\n",
    "\n",
    "You can download the `minkloc3d_nclt.pth` from the HuggingFace model hub:\n",
    "https://huggingface.co/OPR-Project/PlaceRecognition-NCLT.\n",
    "\n",
    "```bash\n",
    "wget https://huggingface.co/OPR-Project/PlaceRecognition-NCLT/resolve/main/minkloc3d_nclt.pth\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset download\n",
    "\n",
    "You can download the dataset:\n",
    "\n",
    "- Kaggle:\n",
    "  - [ITLP Campus Indoor](https://www.kaggle.com/datasets/alexandermelekhin/itlp-campus-indoor)\n",
    "- Hugging Face:\n",
    "  - [ITLP Campus Indoor](https://huggingface.co/datasets/OPR-Project/ITLP-Campus-Indoor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opr.datasets.itlp import ITLPCampus\n",
    "\n",
    "QUERY_LABELS_PATH = \"/home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_indoor/01_2023-11-09-twilight/text_labels.json\" \n",
    "DB_LABELS_PATH = \"/home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_indoor/00_2023-10-25-night/text_labels.json\"\n",
    "\n",
    "QUERY_TRACK_DIR = \"/home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_indoor/01_2023-11-09-twilight\"\n",
    "DATABASE_TRACK_DIR = \"/home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_indoor/00_2023-10-25-night\"\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "MODEL_CONFIG_PATH = \"../configs/model/place_recognition/minkloc3d.yaml\"\n",
    "WEIGHTS_PATH = \"../weights/place_recognition/minkloc3d_nclt.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dataset = ITLPCampus(\n",
    "    dataset_root=QUERY_TRACK_DIR,\n",
    "    sensors=[\"lidar\"],\n",
    "    mink_quantization_size=0.5,\n",
    "    load_semantics=False,\n",
    "    load_text_descriptions=False,\n",
    "    load_text_labels=False,\n",
    "    load_aruco_labels=False,\n",
    "    indoor=True,\n",
    ")\n",
    "\n",
    "db_dataset = ITLPCampus(\n",
    "    dataset_root=DATABASE_TRACK_DIR,\n",
    "    sensors=[\"lidar\"],\n",
    "    indoor=True,\n",
    ")\n",
    "\n",
    "with open(QUERY_LABELS_PATH, \"rb\") as f:\n",
    "    query_labels = json.load(f)\n",
    "    query_labels = json.loads(query_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = OmegaConf.load(MODEL_CONFIG_PATH)\n",
    "model = instantiate(model_config)\n",
    "\n",
    "pipe = TextLabelsPlaceRecognitionPipeline(\n",
    "    db_labels_path=DB_LABELS_PATH,\n",
    "    database_dir=DATABASE_TRACK_DIR,\n",
    "    model=model,\n",
    "    model_weights_path=WEIGHTS_PATH,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "default_pipe = PlaceRecognitionPipeline(\n",
    "    database_dir=DATABASE_TRACK_DIR,\n",
    "    model=model,\n",
    "    model_weights_path=WEIGHTS_PATH,\n",
    "    device=DEVICE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_i = pipe.database_df[pipe.database_df[\"timestamp\"] == 1698265583792060160]\n",
    "pred_i.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 914\n",
    "\n",
    "timestamp = list(query_labels.keys())[id]\n",
    "query_annos = get_labels_by_id(query_labels, timestamp)\n",
    "print(f\"query_annos = {query_annos}\")\n",
    "\n",
    "sample_data = query_dataset[id]\n",
    "sample_pose_gt = sample_data.pop(\"pose\") \n",
    "\n",
    "sample_output = pipe.infer(sample_data, query_annos)\n",
    "\n",
    "print(f\"sample_output.keys() = {sample_output.keys()}\")\n",
    "print(f\"sample_output['idx'] = {sample_output['idx']}\")\n",
    "print(f\"pose = {sample_output['pose']}\")\n",
    "print(f\"pose_gt = {sample_pose_gt.numpy()}\")\n",
    "\n",
    "dist_error, angle_error = compute_error(sample_output[\"pose\"], sample_pose_gt.numpy())\n",
    "print(f\"dist_error = {dist_error}, angle_error = {angle_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from geotransformer.utils.registration import compute_registration_error\n",
    "from geotransformer.utils.pointcloud import get_transform_from_rotation_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_MATCH_THRESHOLD = 25.0\n",
    "pr_matches = []\n",
    "rre_list = []\n",
    "rte_list = []\n",
    "times = []\n",
    "\n",
    "\n",
    "for id in tqdm(range(len(query_labels))):\n",
    "    timestamp = list(query_labels.keys())[id]\n",
    "    query_annos = get_labels_by_id(query_labels, timestamp)\n",
    "    data = query_dataset[id]\n",
    "    gt_pose = data.pop(\"pose\") \n",
    "    gt_pose = get_transform_from_rotation_translation(Rotation.from_quat(gt_pose[3:]).as_matrix(), gt_pose[:3])\n",
    "\n",
    "    start_time = time.time()\n",
    "    pipe_out = pipe.infer(data, query_annos)\n",
    "    times.append(time.time() - start_time)\n",
    "    \n",
    "    estimated_pose = pipe_out[\"pose\"]\n",
    "    estimated_pose = get_transform_from_rotation_translation(Rotation.from_quat(estimated_pose[3:]).as_matrix(), estimated_pose[:3])\n",
    "\n",
    "    _, db_match_distance = compute_registration_error(gt_pose, estimated_pose)\n",
    "    pr_matched = db_match_distance <= PR_MATCH_THRESHOLD\n",
    "    pr_matches.append(pr_matched)\n",
    "    \n",
    "    if pr_matched:\n",
    "        rre, rte = compute_registration_error(gt_pose, estimated_pose)\n",
    "        rre_list.append(rre)\n",
    "        rte_list.append(rte)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PlaceRecognition R@1 = {np.mean(pr_matches):0.3f}\")\n",
    "print(f\"Localization Mean RRE = {np.mean(rre_list):0.3f}\")\n",
    "print(f\"Localization Mean RTE = {np.mean(rte_list):0.3f}\")\n",
    "\n",
    "print(f\"Localization Median RRE = {np.median(rre_list):0.3f}\")\n",
    "print(f\"Localization Median RTE = {np.median(rte_list):0.3f}\")\n",
    "\n",
    "print(f\"Mean Time = {(np.mean(times) * 1000):0.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pr_matches), len(rre_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results only on frames with text labels (TextLabelsPlaceRecognitionPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_MATCH_THRESHOLD = 25.0\n",
    "pr_matches = []\n",
    "rre_list = []\n",
    "rte_list = []\n",
    "times = []\n",
    "\n",
    "\n",
    "for id in tqdm(range(len(query_labels))):\n",
    "    timestamp = list(query_labels.keys())[id]\n",
    "    query_annos = get_labels_by_id(query_labels, timestamp)\n",
    "    \n",
    "    if len(query_annos) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        data = query_dataset[id]\n",
    "        gt_pose = data.pop(\"pose\") \n",
    "        gt_pose = get_transform_from_rotation_translation(Rotation.from_quat(gt_pose[3:]).as_matrix(), gt_pose[:3])\n",
    "\n",
    "        start_time = time.time()\n",
    "        pipe_out = pipe.infer(data, query_annos)\n",
    "        times.append(time.time() - start_time)\n",
    "        \n",
    "        estimated_pose = pipe_out[\"pose\"]\n",
    "        estimated_pose = get_transform_from_rotation_translation(Rotation.from_quat(estimated_pose[3:]).as_matrix(), estimated_pose[:3])\n",
    "\n",
    "        _, db_match_distance = compute_registration_error(gt_pose, estimated_pose)\n",
    "        pr_matched = db_match_distance <= PR_MATCH_THRESHOLD\n",
    "        pr_matches.append(pr_matched)\n",
    "        \n",
    "        if pr_matched:\n",
    "            rre, rte = compute_registration_error(gt_pose, estimated_pose)\n",
    "            rre_list.append(rre)\n",
    "            rte_list.append(rte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PlaceRecognition R@1 = {np.mean(pr_matches):0.3f}\")\n",
    "print(f\"Localization Mean RRE = {np.mean(rre_list):0.3f}\")\n",
    "print(f\"Localization Mean RTE = {np.mean(rte_list):0.3f}\")\n",
    "\n",
    "print(f\"Localization Median RRE = {np.median(rre_list):0.3f}\")\n",
    "print(f\"Localization Median RTE = {np.median(rte_list):0.3f}\")\n",
    "\n",
    "print(f\"Mean Time = {(np.mean(times) * 1000):0.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pr_matches), len(rre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(query_dataset), len(pr_matches) / len(query_dataset) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results only on frames with text labels (PlaceRecognitionPipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_MATCH_THRESHOLD = 25.0\n",
    "pr_matches = []\n",
    "rre_list = []\n",
    "rte_list = []\n",
    "times = []\n",
    "\n",
    "\n",
    "for id in tqdm(range(len(query_labels))):\n",
    "    timestamp = list(query_labels.keys())[id]\n",
    "    query_annos = get_labels_by_id(query_labels, timestamp)\n",
    "    \n",
    "    if len(query_annos) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        data = query_dataset[id]\n",
    "        gt_pose = data.pop(\"pose\") \n",
    "        gt_pose = get_transform_from_rotation_translation(Rotation.from_quat(gt_pose[3:]).as_matrix(), gt_pose[:3])\n",
    "\n",
    "        start_time = time.time()\n",
    "        pipe_out = default_pipe.infer(data)\n",
    "        times.append(time.time() - start_time)\n",
    "        \n",
    "        estimated_pose = pipe_out[\"pose\"]\n",
    "        estimated_pose = get_transform_from_rotation_translation(Rotation.from_quat(estimated_pose[3:]).as_matrix(), estimated_pose[:3])\n",
    "\n",
    "        _, db_match_distance = compute_registration_error(gt_pose, estimated_pose)\n",
    "        pr_matched = db_match_distance <= PR_MATCH_THRESHOLD\n",
    "        pr_matches.append(pr_matched)\n",
    "        \n",
    "        if pr_matched:\n",
    "            rre, rte = compute_registration_error(gt_pose, estimated_pose)\n",
    "            rre_list.append(rre)\n",
    "            rte_list.append(rte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PlaceRecognition R@1 = {np.mean(pr_matches):0.3f}\")\n",
    "print(f\"Localization Mean RRE = {np.mean(rre_list):0.3f}\")\n",
    "print(f\"Localization Mean RTE = {np.mean(rte_list):0.3f}\")\n",
    "\n",
    "print(f\"Localization Median RRE = {np.median(rre_list):0.3f}\")\n",
    "print(f\"Localization Median RTE = {np.median(rte_list):0.3f}\")\n",
    "\n",
    "print(f\"Mean Time = {(np.mean(times) * 1000):0.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pr_matches), len(rre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
