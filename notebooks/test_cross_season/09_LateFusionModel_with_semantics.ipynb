{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LateFusionModel with semantics - ITLP dataset test\n",
    "\n",
    "A module that implements a neural network algorithm for searching a database of places already visited by a vehicle for the most similar records using sequences of data from lidars and cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-01 12:42:13.249\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mopr.models.place_recognition.pointmamba\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[33m\u001b[1mThe 'pointmamba' package is not installed. Please install it manually if neccessary.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import open3d.core as o3c\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_metric_learning.distances import LpDistance\n",
    "\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "from scipy.spatial.transform import Rotation\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from opr.datasets.itlp import ITLPCampus\n",
    "from opr.models.place_recognition.base import LateFusionModel\n",
    "from opr.testing import get_recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DISPLAY\"] = \":1\"\n",
    "\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "\n",
    "# def compute_error(estimated_pose, gt_pose):\n",
    "#     \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "#     estimated_pose = pose_to_matrix(estimated_pose)\n",
    "#     gt_pose = pose_to_matrix(gt_pose)\n",
    "#     return compute_registration_error(estimated_pose, gt_pose)\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return angle_error, dist_error\n",
    "\n",
    "\n",
    "def draw_pc(pc: Tensor, color: str = \"blue\"):\n",
    "    pc_o3d = o3c.Tensor.from_dlpack(torch.utils.dlpack.to_dlpack(pc))\n",
    "    pcd = o3d.t.geometry.PointCloud(pc_o3d)\n",
    "    if color == \"blue\":\n",
    "        c = [0.0, 0.0, 1.0]\n",
    "    elif color == \"red\":\n",
    "        c = [1.0, 0.0, 0.0]\n",
    "    else:\n",
    "        c = [0.0, 1.0, 0.0]\n",
    "    pcd = pcd.paint_uniform_color(c)\n",
    "    o3d.visualization.draw_geometries(\n",
    "        [pcd.to_legacy()],\n",
    "    )\n",
    "\n",
    "\n",
    "def invert_rigid_transformation_matrix(T: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inverts a 4x4 rigid body transformation matrix.\n",
    "\n",
    "    Args:\n",
    "        T (np.ndarray): A 4x4 rigid body transformation matrix.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The inverted 4x4 rigid body transformation matrix.\n",
    "    \"\"\"\n",
    "    assert T.shape == (4, 4), \"Input matrix must be 4x4.\"\n",
    "\n",
    "    R = T[:3, :3]\n",
    "    t = T[:3, 3]\n",
    "\n",
    "    R_inv = R.T\n",
    "    t_inv = -R.T @ t\n",
    "\n",
    "    T_inv = np.eye(4)\n",
    "    T_inv[:3, :3] = R_inv\n",
    "    T_inv[:3, 3] = t_inv\n",
    "\n",
    "    return T_inv\n",
    "\n",
    "\n",
    "def draw_pc_pair(\n",
    "    pc_blue: Tensor, pc_blue_pose: np.ndarray | Tensor, pc_red: Tensor, pc_red_pose: np.ndarray | Tensor\n",
    "):\n",
    "    pc_blue_o3d = o3c.Tensor.from_dlpack(torch.utils.dlpack.to_dlpack(copy.deepcopy(pc_blue)))\n",
    "    pc_red_o3d = o3c.Tensor.from_dlpack(torch.utils.dlpack.to_dlpack(copy.deepcopy(pc_red)))\n",
    "\n",
    "    blue_pcd = o3d.t.geometry.PointCloud(pc_blue_o3d)\n",
    "    blue_pcd_tmp = copy.deepcopy(blue_pcd)\n",
    "\n",
    "    red_pcd = o3d.t.geometry.PointCloud(pc_red_o3d)\n",
    "    red_pcd_tmp = copy.deepcopy(red_pcd)\n",
    "\n",
    "    blue_pcd_tmp.voxel_down_sample(voxel_size=0.3)\n",
    "    # blue_pcd_tmp.transform(pose_to_matrix(pc_blue_pose))\n",
    "    blue_pcd_tmp = blue_pcd_tmp.paint_uniform_color([0.0, 0.0, 1.0])\n",
    "\n",
    "    red_pcd_tmp.voxel_down_sample(voxel_size=0.3)\n",
    "    red_pcd_tmp.transform(pose_to_matrix(pc_red_pose))\n",
    "    red_pcd_tmp.transform(invert_rigid_transformation_matrix(pose_to_matrix(pc_blue_pose)))\n",
    "    red_pcd_tmp = red_pcd_tmp.paint_uniform_color([1.0, 0.0, 0.0])\n",
    "    o3d.visualization.draw_geometries(\n",
    "        [blue_pcd_tmp.to_legacy(), red_pcd_tmp.to_legacy()],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can **download the dataset**:\n",
    "\n",
    "- Kaggle:\n",
    "  - [ITLP Campus Outdoor](https://www.kaggle.com/datasets/alexandermelekhin/itlp-campus-outdoor)\n",
    "- Hugging Face:\n",
    "  - [ITLP Campus Outdoor](https://huggingface.co/datasets/OPR-Project/ITLP-Campus-Outdoor)\n",
    "\n",
    "To **download the model weights**, run the following command:\n",
    "\n",
    "```bash\n",
    "# place recognition weights\n",
    "wget -O ../../weights/place_recognition/multi-image_multi-semantic_lidar_late-fusion_itlp-finetune.pth https://huggingface.co/OPR-Project/PlaceRecognition-NCLT/resolve/main/multi-image_multi-semantic_lidar_late-fusion_itlp-finetune.pth\n",
    "\n",
    "# registration weights\n",
    "wget -O ../../weights/registration/hregnet_light_feats_nuscenes.pth https://huggingface.co/OPR-Project/Registration-nuScenes/resolve/main/hregnet_light_feats_nuscenes.pth\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place recognition weights\n",
    "!wget -O ../../weights/place_recognition/multi-image_multi-semantic_lidar_late-fusion_itlp-finetune.pth https://huggingface.co/OPR-Project/PlaceRecognition-NCLT/resolve/main/multi-image_multi-semantic_lidar_late-fusion_itlp-finetune.pth\n",
    "\n",
    "# registration weights\n",
    "!wget -O ../../weights/registration/hregnet_light_feats_nuscenes.pth https://huggingface.co/OPR-Project/Registration-nuScenes/resolve/main/hregnet_light_feats_nuscenes.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test track list:\n",
      "['00_2023-02-10', '03_2023-04-11', '05_2023-08-15-day', '07_2023-10-04-day']\n"
     ]
    }
   ],
   "source": [
    "DATASET_ROOT = \"/home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor\"\n",
    "\n",
    "TRACK_LIST = [\n",
    "    \"00_2023-02-10\",\n",
    "    \"03_2023-04-11\",\n",
    "    \"05_2023-08-15-day\",\n",
    "    \"07_2023-10-04-day\",\n",
    "]\n",
    "\n",
    "SEASON_MAPPING = {\n",
    "    \"00_2023-02-10\": \"winter\",\n",
    "    \"03_2023-04-11\": \"spring\",\n",
    "    \"05_2023-08-15-day\": \"summer\",\n",
    "    \"07_2023-10-04-day\": \"fall\",\n",
    "}\n",
    "\n",
    "print(\"Test track list:\")\n",
    "print(TRACK_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_SUITE = [\"front_cam\", \"back_cam\", \"lidar\"]\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "PR_MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_multi-semantic_lidar_late-fusion.yaml\"\n",
    "PR_WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_multi-semantic_lidar_late-fusion_itlp-finetune.pth\"\n",
    "\n",
    "REGISTRATION_MODEL_CONFIG_PATH = \"../../configs/model/registration/hregnet_light_feats.yaml\"\n",
    "REGISTRATION_WEIGHTS_PATH = \"../../weights/registration/hregnet_light_feats_nuscenes.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_model_config = OmegaConf.load(PR_MODEL_CONFIG_PATH)\n",
    "pr_model = instantiate(pr_model_config)\n",
    "pr_model.load_state_dict(torch.load(PR_WEIGHTS_PATH))\n",
    "pr_model = pr_model.to(DEVICE)\n",
    "pr_model.eval();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ITLPCampus(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    csv_file=\"full_test.csv\",\n",
    "    sensors=SENSOR_SUITE,\n",
    "    load_semantics=True,\n",
    ")\n",
    "dataset.dataset_df = dataset.dataset_df[dataset.dataset_df[\"track\"].isin(TRACK_LIST)]\n",
    "dataset.dataset_df.reset_index(inplace=True)\n",
    "\n",
    "no_masks = []\n",
    "no_masks_filenames = []\n",
    "\n",
    "for index, row in dataset.dataset_df.iterrows():\n",
    "    mask_path = f\"{DATASET_ROOT}/{row['track']}/masks/back_cam/{row['back_cam_ts']}.png\"\n",
    "    filename = f\"{row['back_cam_ts']}.png\"\n",
    "    if not Path(mask_path).exists():\n",
    "        no_masks.append(index)\n",
    "        no_masks_filenames.append(filename)\n",
    "\n",
    "dataset.dataset_df.drop(no_masks, inplace=True)\n",
    "dataset.dataset_df.reset_index(inplace=True)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=dataset.collate_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings_list = []\n",
    "    for batch in tqdm(dataloader, desc=\"Calculating test set descriptors\", leave=False):\n",
    "        batch = {e: batch[e].to(DEVICE) for e in batch}\n",
    "        embeddings = pr_model(batch)[\"final_descriptor\"]\n",
    "        embeddings_list.append(embeddings.cpu().numpy())\n",
    "        torch.cuda.empty_cache()\n",
    "    test_embeddings = np.vstack(embeddings_list)\n",
    "\n",
    "test_df = dataloader.dataset.dataset_df\n",
    "\n",
    "queries = []\n",
    "databases = []\n",
    "for _, group in test_df.groupby(\"track\"):\n",
    "    databases.append(group.index.to_list())\n",
    "    queries.append(group.index.to_list())\n",
    "\n",
    "utms = torch.tensor(test_df[[\"tx\", \"ty\"]].to_numpy())\n",
    "dist_fn = LpDistance(normalize_embeddings=False)\n",
    "dist_utms = dist_fn(utms).numpy()\n",
    "\n",
    "\n",
    "ij_permutations = list(itertools.permutations(range(len(queries)), 2))\n",
    "top1_distances = {}\n",
    "\n",
    "for i, j in tqdm(ij_permutations, desc=\"Calculating metrics\", leave=False):\n",
    "    query = queries[i]\n",
    "    database = databases[j]\n",
    "    query_embs = test_embeddings[query]\n",
    "    database_embs = test_embeddings[database]\n",
    "\n",
    "    distances = dist_utms[query][:, database]\n",
    "    _, _, top1_distance = get_recalls(query_embs, database_embs, distances, at_n=10, dist_thresh=25.0)\n",
    "    top1_distances[f\"query {SEASON_MAPPING[TRACK_LIST[i]]}, db {SEASON_MAPPING[TRACK_LIST[j]]}\"] = top1_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query winter, db spring:  1.2469\n",
      "query winter, db summer:  1.4443\n",
      "query winter, db fall:  1.2988\n",
      "query spring, db winter:  1.2459\n",
      "query spring, db summer:  1.3384\n",
      "query spring, db fall:  1.3051\n",
      "query summer, db winter:  1.4683\n",
      "query summer, db spring:  1.3748\n",
      "query summer, db fall:  1.2435\n",
      "query fall, db winter:  1.3260\n",
      "query fall, db spring:  1.3288\n",
      "query fall, db summer:  1.2412\n"
     ]
    }
   ],
   "source": [
    "for k, v in top1_distances.items():\n",
    "    print(f\"{k}:  {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3218380209495755"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(top1_distances.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
