{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import cv2\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.spatial.transform import Rotation\n",
    "from geotransformer.utils.pointcloud import get_transform_from_rotation_translation\n",
    "\n",
    "from opr.datasets.itlp import ITLPCampus\n",
    "from opr.pipelines.localization import ArucoLocalizationPipeline\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline\n",
    "from opr.pipelines.registration import PointcloudRegistrationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return angle_error, dist_error\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can **download the dataset**:\n",
    "\n",
    "- Kaggle:\n",
    "  - [ITLP Campus Outdoor](https://www.kaggle.com/datasets/alexandermelekhin/itlp-campus-outdoor)\n",
    "- Hugging Face:\n",
    "  - [ITLP Campus Outdoor](https://huggingface.co/datasets/OPR-Project/ITLP-Campus-Outdoor)\n",
    "\n",
    "To **download the model weights**, run the following command:\n",
    "\n",
    "```bash\n",
    "# place recognition weights\n",
    "wget -O ../../weights/place_recognition/multi-image_lidar_late-fusion_itlp-finetune.pth https://huggingface.co/OPR-Project/PlaceRecognition-NCLT/resolve/main/multi-image_lidar_late-fusion_itlp-finetune.pth\n",
    "\n",
    "# registration weights\n",
    "wget -O ../../weights/registration/hregnet_light_feats_nuscenes.pth https://huggingface.co/OPR-Project/Registration-nuScenes/resolve/main/hregnet_light_feats_nuscenes.pth\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place recognition weights\n",
    "!wget -O ../../weights/place_recognition/multi-image_lidar_late-fusion_itlp-finetune.pth https://huggingface.co/OPR-Project/PlaceRecognition-NCLT/resolve/main/multi-image_lidar_late-fusion_itlp-finetune.pth\n",
    "\n",
    "# registration weights\n",
    "!wget -O ../../weights/registration/hregnet_light_feats_nuscenes.pth https://huggingface.co/OPR-Project/Registration-nuScenes/resolve/main/hregnet_light_feats_nuscenes.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test track list:\n",
      "['00_2023-02-10', '03_2023-04-11', '05_2023-08-15-day', '07_2023-10-04-day']\n"
     ]
    }
   ],
   "source": [
    "DATASET_ROOT = \"/home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor\"\n",
    "SENSOR_SUITE = [\"front_cam\", \"back_cam\", \"lidar\"]\n",
    "\n",
    "TRACK_LIST = [\n",
    "    \"00_2023-02-10\",\n",
    "    \"03_2023-04-11\",\n",
    "    \"05_2023-08-15-day\",\n",
    "    \"07_2023-10-04-day\",\n",
    "]\n",
    "\n",
    "SEASON_MAPPING = {\n",
    "    \"00_2023-02-10\": \"winter\",\n",
    "    \"03_2023-04-11\": \"spring\",\n",
    "    \"05_2023-08-15-day\": \"summer\",\n",
    "    \"07_2023-10-04-day\": \"fall\",\n",
    "}\n",
    "\n",
    "print(\"Test track list:\")\n",
    "print(TRACK_LIST)\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_dataset = ITLPCampus(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    csv_file=\"aruco_full_test.csv\",\n",
    "    sensors=SENSOR_SUITE,\n",
    ")\n",
    "test_db_dataset = ITLPCampus(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    csv_file=\"full_test.csv\",\n",
    "    sensors=SENSOR_SUITE,\n",
    ")\n",
    "test_db_dataset.dataset_df = test_db_dataset.dataset_df[test_db_dataset.dataset_df[\"track\"].isin(TRACK_LIST)]\n",
    "test_db_dataset.dataset_df.reset_index(inplace=True)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    test_db_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=test_db_dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "PR_WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_lidar_late-fusion_itlp-finetune.pth\"\n",
    "\n",
    "pr_model_config = OmegaConf.load(PR_MODEL_CONFIG_PATH)\n",
    "pr_model = instantiate(pr_model_config)\n",
    "pr_model.load_state_dict(torch.load(PR_WEIGHTS_PATH))\n",
    "pr_model = pr_model.to(DEVICE)\n",
    "pr_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [00:04<00:00, 33.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor/00_2023-02-10/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor/03_2023-04-11/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor/05_2023-08-15-day/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor/07_2023-10-04-day/index.faiss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        final_descriptor = pr_model(batch)[\"final_descriptor\"]\n",
    "        descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "descriptors = np.concatenate(descriptors, axis=0)\n",
    "\n",
    "dataset_df = test_db_dataset.dataset_df\n",
    "for track, indices in dataset_df.groupby(\"track\").groups.items():\n",
    "    track_descriptors = descriptors[indices]\n",
    "    track_index = faiss.IndexFlatL2(track_descriptors.shape[1])\n",
    "    track_index.add(track_descriptors)\n",
    "    faiss.write_index(track_index, f\"{DATASET_ROOT}/{track}/index.faiss\")\n",
    "    print(f\"Saved index {DATASET_ROOT}/{track}/index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_metadata = {\n",
    "    \"front_cam_intrinsics\": [[683.6199340820312, 0.0, 615.1160278320312],\n",
    "                             [0.0, 683.6199340820312, 345.32354736328125],\n",
    "                             [0.0, 0.0, 1.0]],\n",
    "    \"front_cam_distortion\": [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    \"front_cam2baselink\": [-0.2388, 0.06, 0.75, -0.5, 0.49999999999755174, -0.5, 0.5000000000024483],\n",
    "    \"back_cam_intrinsics\": [[910.4178466796875, 0.0, 648.44140625],\n",
    "                            [0.0, 910.4166870117188, 354.0118408203125],\n",
    "                            [0.0, 0.0, 1.0]],\n",
    "    \"back_cam_distortion\": [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    \"back_cam2baselink\": [-0.3700594606670597, -0.006647301538708517, 0.7427924789987381, -0.4981412857230513, -0.4907829006275322, 0.5090864815669471, 0.5018149813673275]\n",
    "}\n",
    "\n",
    "aruco_metadata = {\n",
    "    \"aruco_type\": cv2.aruco.DICT_4X4_250,\n",
    "    \"aruco_size\": 0.2,\n",
    "    \"aruco_gt_pose_by_id\": {\n",
    "        0: [-23.76325316, 16.94296093, 1.51796168, 0.25454437, 0.65070725, 0.6526984, 0.29286864],\n",
    "        2: [-8.81475372, -12.47510287, 1.75787052, 0.61022095, -0.21494468, -0.21004688, 0.73301397],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRATION_MODEL_CONFIG_PATH = \"../../configs/model/registration/hregnet_light_feats.yaml\"\n",
    "REGISTRATION_WEIGHTS_PATH = \"../../weights/registration/hregnet_light_feats_nuscenes.pth\"\n",
    "\n",
    "reg_model_config = OmegaConf.load(REGISTRATION_MODEL_CONFIG_PATH)\n",
    "reg_model = instantiate(reg_model_config)\n",
    "reg_model.load_state_dict(torch.load(REGISTRATION_WEIGHTS_PATH))\n",
    "reg_model = reg_model.to(DEVICE)\n",
    "reg_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECALL_THRESHOLD = 25.0\n",
    "\n",
    "all_reg_recalls_aruco = {}\n",
    "all_mean_reg_rotation_errors_aruco = {}\n",
    "all_mean_reg_translation_errors_aruco = {}\n",
    "all_median_reg_rotation_errors_aruco = {}\n",
    "all_median_reg_translation_errors_aruco = {}\n",
    "all_times_aruco = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 21.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [0] on image_front_cam\n",
      "Utilize Aruco with id [0] on image_front_cam for pose estimation due min distanse\n",
      "Detect Aruco with id [0] on image_front_cam\n",
      "Utilize Aruco with id [0] on image_front_cam for pose estimation due min distanse\n",
      "Detect Aruco with id [0] on image_front_cam\n",
      "Utilize Aruco with id [0] on image_front_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 15.29it/s]\n",
      "3it [00:00, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  9.67it/s]\n",
      "4it [00:00, 13.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [0] on image_back_cam\n",
      "Utilize Aruco with id [0] on image_back_cam for pose estimation due min distanse\n",
      "Detect Aruco with id [0] on image_back_cam\n",
      "Utilize Aruco with id [0] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [0] on image_front_cam\n",
      "Utilize Aruco with id [0] on image_front_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 12.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [0] on image_back_cam\n",
      "Utilize Aruco with id [0] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 10.09it/s]\n",
      "2it [00:00, 14.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 10.70it/s]\n",
      "4it [00:00, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [0] on image_back_cam\n",
      "Utilize Aruco with id [0] on image_back_cam for pose estimation due min distanse\n",
      "Detect Aruco with id [0] on image_back_cam\n",
      "Utilize Aruco with id [0] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [0] on image_front_cam\n",
      "Utilize Aruco with id [0] on image_front_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 12.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [0] on image_back_cam\n",
      "Utilize Aruco with id [0] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 10.24it/s]\n",
      "3it [00:00, 25.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [0] on image_front_cam\n",
      "Utilize Aruco with id [0] on image_front_cam for pose estimation due min distanse\n",
      "Detect Aruco with id [0] on image_front_cam\n",
      "Utilize Aruco with id [0] on image_front_cam for pose estimation due min distanse\n",
      "Detect Aruco with id [0] on image_front_cam\n",
      "Utilize Aruco with id [0] on image_front_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 16.77it/s]\n",
      "4it [00:00, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [0] on image_back_cam\n",
      "Utilize Aruco with id [0] on image_back_cam for pose estimation due min distanse\n",
      "Detect Aruco with id [0] on image_back_cam\n",
      "Utilize Aruco with id [0] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [0] on image_front_cam\n",
      "Utilize Aruco with id [0] on image_front_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 12.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [0] on image_back_cam\n",
      "Utilize Aruco with id [0] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  9.88it/s]\n",
      "3it [00:00, 22.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [0] on image_front_cam\n",
      "Utilize Aruco with id [0] on image_front_cam for pose estimation due min distanse\n",
      "Detect Aruco with id [0] on image_front_cam\n",
      "Utilize Aruco with id [0] on image_front_cam for pose estimation due min distanse\n",
      "Detect Aruco with id [0] on image_front_cam\n",
      "Utilize Aruco with id [0] on image_front_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 16.12it/s]\n",
      "2it [00:00, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00, 10.39it/s]\n",
      "4it [00:00, 10.39it/s]\n"
     ]
    }
   ],
   "source": [
    "for db_track in TRACK_LIST:\n",
    "    pr_pipe = PlaceRecognitionPipeline(\n",
    "        database_dir=Path(DATASET_ROOT) / db_track,\n",
    "        model=pr_model,\n",
    "        model_weights_path=PR_WEIGHTS_PATH,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    for query_track in TRACK_LIST:\n",
    "        if db_track == query_track:\n",
    "            continue\n",
    "\n",
    "        reg_pipe = PointcloudRegistrationPipeline(\n",
    "            model=reg_model,\n",
    "            model_weights_path=REGISTRATION_WEIGHTS_PATH,\n",
    "            device=DEVICE,\n",
    "            voxel_downsample_size=0.3,\n",
    "            num_points_downsample=8192,\n",
    "        )\n",
    "        loc_pipe = ArucoLocalizationPipeline(\n",
    "            place_recognition_pipeline=pr_pipe,\n",
    "            registration_pipeline=reg_pipe,\n",
    "            precomputed_reg_feats=True,\n",
    "            pointclouds_subdir=\"lidar\",\n",
    "            aruco_metadata=aruco_metadata,\n",
    "            camera_metadata=camera_metadata,\n",
    "            fastest=False,\n",
    "            use_first_marker=True\n",
    "        )\n",
    "\n",
    "        query_dataset = copy.deepcopy(test_query_dataset)\n",
    "        query_dataset.dataset_df = query_dataset.dataset_df[query_dataset.dataset_df[\"track\"] == query_track].reset_index(drop=True)\n",
    "        query_df = query_dataset.dataset_df\n",
    "        ###\n",
    "        # specific for aruco\n",
    "        query_dataset.image_transform = lambda x: x\n",
    "\n",
    "        db_dataset = copy.deepcopy(test_db_dataset)\n",
    "        db_dataset.dataset_df = db_dataset.dataset_df[db_dataset.dataset_df[\"track\"] == db_track].reset_index(drop=True)\n",
    "        db_df = db_dataset.dataset_df\n",
    "        ###\n",
    "        # specific for aruco\n",
    "        db_dataset.image_transform = lambda x: x\n",
    "        warmup_sample = db_dataset[0]\n",
    "\n",
    "        loc_pipe.pr_pipe.database_df = db_df\n",
    "        loc_pipe.database_df = db_df\n",
    "\n",
    "        reg_matches_aruco = []\n",
    "        reg_rotation_errors_aruco = []\n",
    "        reg_translation_errors_aruco = []\n",
    "        times_aruco = []\n",
    "\n",
    "        # fake launch to run first long call of torch model\n",
    "        _ = loc_pipe.loc_part(warmup_sample)\n",
    "\n",
    "        for q_i, query in tqdm(enumerate(query_dataset)):\n",
    "            query_pose = query_df.iloc[q_i][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "            start = time()\n",
    "            output = loc_pipe.infer(query)\n",
    "            torch.cuda.current_stream().synchronize()\n",
    "            step_time = time() - start\n",
    "            times_aruco.append(step_time)\n",
    "\n",
    "            estimated_pose = output[\"pose_by_aruco\"] if output[\"pose_by_aruco\"] is not None else output[\"pose_by_place_recognition\"]\n",
    "\n",
    "            reg_rotation_error_aruco, reg_translation_error_aruco = compute_error(estimated_pose, query_pose)\n",
    "            reg_correct_aruco = reg_translation_error_aruco < RECALL_THRESHOLD\n",
    "            reg_matches_aruco.append(reg_correct_aruco)\n",
    "            reg_rotation_errors_aruco.append(reg_rotation_error_aruco)\n",
    "            reg_translation_errors_aruco.append(reg_translation_error_aruco)\n",
    "\n",
    "        key_str = f\"DB {SEASON_MAPPING[db_track]}, Query {SEASON_MAPPING[query_track]}\"\n",
    "        all_reg_recalls_aruco[key_str] = np.nanmean(reg_matches_aruco)\n",
    "        all_mean_reg_rotation_errors_aruco[key_str] = np.nanmean(reg_rotation_errors_aruco)\n",
    "        all_mean_reg_translation_errors_aruco[key_str] = np.nanmean(reg_translation_errors_aruco)\n",
    "        all_median_reg_rotation_errors_aruco[key_str] = np.nanmedian(reg_rotation_errors_aruco)\n",
    "        all_median_reg_translation_errors_aruco[key_str] = np.nanmedian(reg_translation_errors_aruco)\n",
    "        all_times_aruco.extend(times_aruco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1:\n",
      "DB winter, Query spring: 100.00\n",
      "DB winter, Query summer: 100.00\n",
      "DB winter, Query fall: 100.00\n",
      "DB spring, Query winter: 75.00\n",
      "DB spring, Query summer: 100.00\n",
      "DB spring, Query fall: 100.00\n",
      "DB summer, Query winter: 100.00\n",
      "DB summer, Query spring: 100.00\n",
      "DB summer, Query fall: 100.00\n",
      "DB fall, Query winter: 100.00\n",
      "DB fall, Query spring: 100.00\n",
      "DB fall, Query summer: 100.00\n",
      "Mean: 97.92\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall@1:\")\n",
    "for key, value in all_reg_recalls_aruco.items():\n",
    "    print(f\"{key}: {value*100:.2f}\")\n",
    "\n",
    "print(f\"Mean: {np.nanmean(list(all_reg_recalls_aruco.values()))*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median RRE:\n",
      "DB winter, Query spring: 12.64\n",
      "DB winter, Query summer: 19.51\n",
      "DB winter, Query fall: 5.51\n",
      "DB spring, Query winter: 2.84\n",
      "DB spring, Query summer: 9.02\n",
      "DB spring, Query fall: 15.14\n",
      "DB summer, Query winter: 6.05\n",
      "DB summer, Query spring: 12.64\n",
      "DB summer, Query fall: 3.73\n",
      "DB fall, Query winter: 6.44\n",
      "DB fall, Query spring: 12.64\n",
      "DB fall, Query summer: 12.37\n",
      "Mean: 9.88\n"
     ]
    }
   ],
   "source": [
    "print(\"Median RRE:\")\n",
    "for key, value in all_median_reg_rotation_errors_aruco.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "\n",
    "print(f\"Mean: {np.nanmean(list(all_median_reg_rotation_errors_aruco.values())):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median RTE:\n",
      "DB winter, Query spring: 4.06\n",
      "DB winter, Query summer: 4.21\n",
      "DB winter, Query fall: 3.59\n",
      "DB spring, Query winter: 3.28\n",
      "DB spring, Query summer: 2.33\n",
      "DB spring, Query fall: 3.50\n",
      "DB summer, Query winter: 2.43\n",
      "DB summer, Query spring: 4.35\n",
      "DB summer, Query fall: 2.85\n",
      "DB fall, Query winter: 3.68\n",
      "DB fall, Query spring: 4.30\n",
      "DB fall, Query summer: 1.62\n",
      "Mean: 3.35\n"
     ]
    }
   ],
   "source": [
    "print(\"Median RTE:\")\n",
    "for key, value in all_median_reg_translation_errors_aruco.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "\n",
    "\n",
    "print(f\"Mean: {np.nanmean(list(all_median_reg_translation_errors_aruco.values())):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference time: 56.18 ms\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean inference time: {np.nanmean(all_times_aruco) * 1000:.2f} ms\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
