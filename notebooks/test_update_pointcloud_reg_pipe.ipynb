{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test updated version of PCR pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchshow not installed, skipping visualization\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import open3d.core as o3c\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import torchshow as ts\n",
    "except ImportError:\n",
    "    ts = None\n",
    "    print(\"torchshow not installed, skipping visualization\")\n",
    "\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "from scipy.spatial.transform import Rotation\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from geotransformer.utils.registration import compute_registration_error\n",
    "\n",
    "\n",
    "from opr.datasets import NCLTDataset\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline\n",
    "from opr.pipelines.registration.pointcloud import PointcloudRegistrationPipeline\n",
    "from opr.pipelines.localization import LocalizationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DISPLAY\"] = \":1\"\n",
    "\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights download\n",
    "\n",
    "##### Place Recognition\n",
    "\n",
    "You can download the `multi-image_lidar_late-fusion_nclt.pth` from the HuggingFace model hub:\n",
    "https://huggingface.co/OPR-Project/PlaceRecognition-NCLT\n",
    "\n",
    "```bash\n",
    "wget https://huggingface.co/OPR-Project/PlaceRecognition-NCLT/resolve/main/multi-image_lidar_late-fusion_nclt.pth\n",
    "```\n",
    "\n",
    "##### Registration\n",
    "\n",
    "You can download the `hregnet_nuscenes.pth` from the HuggingFace model hub:\n",
    "https://huggingface.co/OPR-Project/Registration-nuScenes.\n",
    "\n",
    "```bash\n",
    "wget https://huggingface.co/OPR-Project/Registration-nuScenes/resolve/main/hregnet_nuscenes.pth\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed\"\n",
    "\n",
    "SENSOR_SUITE = [\"image_Cam5\", \"image_Cam2\", \"pointcloud_lidar\"]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "PR_MODEL_CONFIG_PATH = \"../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "PR_WEIGHTS_PATH = \"../weights/place_recognition/multi-image_lidar_late-fusion_nclt.pth\"\n",
    "\n",
    "REGISTRATION_MODEL_CONFIG_PATH = \"../configs/model/registration/hregnet.yaml\"\n",
    "REGISTRATION_WEIGHTS_PATH = \"../weights/registration/hregnet_nuscenes.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 tracks\n",
      "['2012-01-08', '2012-01-22', '2012-02-12', '2012-02-18', '2012-03-31', '2012-05-26', '2012-08-04', '2012-10-28', '2012-11-04', '2012-12-01']\n",
      "WARNING: track list limited\n",
      "['2012-01-08', '2012-01-22']\n"
     ]
    }
   ],
   "source": [
    "TRACK_LIST = sorted([str(subdir.name) for subdir in Path(DATASET_ROOT).iterdir() if subdir.is_dir()])\n",
    "print(f\"Found {len(TRACK_LIST)} tracks\")\n",
    "print(TRACK_LIST)\n",
    "\n",
    "print(\"WARNING: track list limited\")\n",
    "TRACK_LIST = TRACK_LIST[:2]\n",
    "print(TRACK_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-24 19:23:00.012\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mopr.models.place_recognition.pointmamba\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[33m\u001b[1mThe 'pointmamba' package is not installed. Please install it manually if neccessary.\u001b[0m\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/docker_opr/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:05<00:00, 8.49MB/s]\n"
     ]
    }
   ],
   "source": [
    "pr_model_config = OmegaConf.load(PR_MODEL_CONFIG_PATH)\n",
    "pr_model = instantiate(pr_model_config)\n",
    "pr_model.load_state_dict(torch.load(PR_WEIGHTS_PATH))\n",
    "pr_model = pr_model.to(DEVICE)\n",
    "pr_model.eval();\n",
    "\n",
    "reg_model_config = OmegaConf.load(REGISTRATION_MODEL_CONFIG_PATH)\n",
    "reg_model = instantiate(reg_model_config)\n",
    "reg_model.load_state_dict(torch.load(REGISTRATION_WEIGHTS_PATH))\n",
    "reg_model = reg_model.to(DEVICE)\n",
    "reg_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed/2012-01-08/HRegNet_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-24 19:23:06.376\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mopr.pipelines.localization.base\u001b[0m:\u001b[36m_setup_precomputed_reg_feats\u001b[0m:\u001b[36m95\u001b[0m - \u001b[33m\u001b[1mPrecomputed registration features directory not found: /home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed/2012-01-08/HRegNet_features. It will be created and features will be computed.\u001b[0m\n",
      "\u001b[32m2025-03-24 19:23:06.376\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mopr.pipelines.localization.base\u001b[0m:\u001b[36m_setup_precomputed_reg_feats\u001b[0m:\u001b[36m105\u001b[0m - \u001b[33m\u001b[1mPrecomputed registration features directory is empty. Computing features.\u001b[0m\n",
      "  0%|          | 0/1261 [00:00<?, ?it/s]\u001b[32m2025-03-24 19:23:06.376\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mopr.pipelines.localization.base\u001b[0m:\u001b[36m_setup_precomputed_reg_feats\u001b[0m:\u001b[36m105\u001b[0m - \u001b[33m\u001b[1mPrecomputed registration features directory is empty. Computing features.\u001b[0m\n",
      "  0%|          | 0/1261 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/hregnet/utils.py:24: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  output = torch.cuda.IntTensor(B, npoint)\n",
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "pr_pipe = PlaceRecognitionPipeline(\n",
    "    database_dir=Path(DATASET_ROOT) / TRACK_LIST[0],\n",
    "    model=pr_model,\n",
    "    model_weights_path=PR_WEIGHTS_PATH,\n",
    "    device=DEVICE,\n",
    ")\n",
    "reg_pipe = PointcloudRegistrationPipeline(\n",
    "    model=reg_model,\n",
    "    model_weights_path=REGISTRATION_WEIGHTS_PATH,\n",
    "    device=DEVICE,\n",
    "    voxel_downsample_size=0.3,\n",
    "    num_points_downsample=8192,\n",
    ")\n",
    "loc_pipe = LocalizationPipeline(\n",
    "    place_recognition_pipeline=pr_pipe,\n",
    "    registration_pipeline=reg_pipe,\n",
    "    precomputed_reg_feats=True,\n",
    "    pointclouds_subdir=\"velodyne_data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dataset = NCLTDataset(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    data_to_load=SENSOR_SUITE,\n",
    "    pointcloud_quantization_size=0.5,\n",
    "    max_point_distance=None,\n",
    ")\n",
    "query_dataset.dataset_df = query_dataset.dataset_df[query_dataset.dataset_df[\"track\"] == TRACK_LIST[1]]\n",
    "query_dataset.dataset_df.reset_index(inplace=True)\n",
    "\n",
    "query_df = pd.read_csv(Path(DATASET_ROOT) / TRACK_LIST[1] / \"track.csv\", index_col=0)\n",
    "query_df = query_df[query_df['image'].isin(query_dataset.dataset_df['image'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/275 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "100%|██████████| 275/275 [00:24<00:00, 11.45it/s]\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "for query in tqdm(query_dataset):\n",
    "    t = time()\n",
    "    output = loc_pipe.infer(query)\n",
    "    times.append(time() - t)\n",
    "times = np.array(times[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['inference_time', 'downsample_time', 'total_time'])\n",
      "54.97 ms\n"
     ]
    }
   ],
   "source": [
    "print(loc_pipe.reg_pipe.stats_history.keys())\n",
    "print(f\"{np.mean(loc_pipe.reg_pipe.stats_history['total_time'][1:]) * 1000:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare downsample performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CPU:   0%|          | 0/275 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU:  11.77 ms\n",
      "GPU:  0.85 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "cpu_times = []\n",
    "for query in tqdm(query_dataset, desc=\"CPU\", leave=False):\n",
    "    query_pc = query[\"pointcloud_lidar_coords\"].to(\"cpu\")\n",
    "    t_s = time()\n",
    "    query_pc_downsampled = reg_pipe._downsample_pointcloud(query_pc)\n",
    "    cpu_times.append(time() - t_s)\n",
    "\n",
    "gpu_times = []\n",
    "for query in tqdm(query_dataset, desc=\"GPU\", leave=False):\n",
    "    query_pc = query[\"pointcloud_lidar_coords\"].to(\"cuda\")\n",
    "    t_s = time()\n",
    "    query_pc_downsampled = reg_pipe._downsample_pointcloud(query_pc)\n",
    "    gpu_times.append(time() - t_s)\n",
    "\n",
    "print(f\"CPU:  {np.mean(cpu_times) * 1000:.2f} ms\")\n",
    "print(f\"GPU:  {np.mean(gpu_times) * 1000:.2f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
