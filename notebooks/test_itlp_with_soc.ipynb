{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Place Recognition and Hierarchical Localization on the ITLP-Campus dataset using `opr.pipelines`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from opr.datasets.itlp import ITLPCampus\n",
    "from opr.models.place_recognition import MinkLoc3D\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinkLoc3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK_LIST = [\n",
    "    \"00_2023-10-25-night\",\n",
    "    \"01_2023-11-09-twilight\",\n",
    "]\n",
    "\n",
    "WEIGHTS_PATH = \"/home/docker_opr/OpenPlaceRecognition/weights/place_recognition/best_soc_oriented.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.experimental import compose, initialize\n",
    "\n",
    "initialize(config_path=\"../configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.utils import instantiate\n",
    "dataloaders = {}\n",
    "\n",
    "for track in TRACK_LIST:\n",
    "    cfg = compose(\"train_soc.yaml\", overrides=[f\"dataset.dataset_root=/home/docker_opr/Datasets/MIPT_campus/indoor/{track}\"])\n",
    "    dataset = instantiate(cfg.dataset, subset=\"test\", csv_file=\"track.csv\")\n",
    "    dataloaders[track] = DataLoader(\n",
    "        dataset, batch_size=16, shuffle=False, num_workers=4, collate_fn=dataset.collate_fn\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opr.models.place_recognition.soc import SOCMLPMixer\n",
    "model = instantiate(cfg.model)\n",
    "model.load_state_dict(torch.load(WEIGHTS_PATH)[\"model_state_dict\"])\n",
    "model = model.to(\"cuda\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for track in TRACK_LIST:\n",
    "    descriptors = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloaders[track]):\n",
    "            batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "            final_descriptor = model(batch)[\"final_descriptor\"]\n",
    "            descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "    descriptors = np.concatenate(descriptors, axis=0)\n",
    "\n",
    "    index = faiss.IndexFlatL2(descriptors.shape[1])\n",
    "    index.add(descriptors)\n",
    "    Path(f\"/home/docker_opr/Datasets/MIPT_campus/indoor/databases/{track}_or\").mkdir(\n",
    "        parents=True, exist_ok=True\n",
    "    )\n",
    "    faiss.write_index(\n",
    "        index, f\"/home/docker_opr/Datasets/MIPT_campus/indoor/databases/{track}_or/index.faiss\"\n",
    "    )\n",
    "\n",
    "    shutil.copy(\n",
    "        f\"/home/docker_opr/Datasets/MIPT_campus/indoor/{track}/track.csv\",\n",
    "        f\"/home/docker_opr/Datasets/MIPT_campus/indoor/databases/{track}_or/track.csv\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy(\n",
    "        f\"/home/docker_opr/Datasets/MIPT_campus/indoor/{track}/track.csv\",\n",
    "        f\"/home/docker_opr/Datasets/MIPT_campus/indoor/databases/{track}_or/track.csv\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test PlaceRecognitionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return dist_error, angle_error\n",
    "\n",
    "def compute_translation_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    gt_trans = gt_pose[:3, 3]\n",
    "    pred_trans = pred_pose[:3, 3]\n",
    "    error = np.linalg.norm(gt_trans - pred_trans)\n",
    "    return error\n",
    "\n",
    "def compute_rotation_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    gt_rot = Rotation.from_matrix(gt_pose[:3, :3])\n",
    "    pred_rot = Rotation.from_matrix(pred_pose[:3, :3])\n",
    "    error = Rotation.inv(gt_rot) * pred_rot\n",
    "    error = error.as_euler('xyz', degrees=True)\n",
    "    error = np.linalg.norm(error)\n",
    "    return error\n",
    "\n",
    "def compute_absolute_pose_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    rotation_error = compute_rotation_error(gt_pose, pred_pose)\n",
    "    translation_error = compute_translation_error(gt_pose, pred_pose)\n",
    "    return rotation_error, translation_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geotransformer.utils.registration import compute_registration_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ij_permutations = list(itertools.permutations(range(len(TRACK_LIST)), 2))\n",
    "\n",
    "median_dist_errors = []\n",
    "median_angle_errors = []\n",
    "mean_dist_errors = []\n",
    "mean_angle_errors = []\n",
    "pr_matches = []\n",
    "PR_MATCH_THRESHOLD = 25.0\n",
    "times = []\n",
    "\n",
    "for i, j in tqdm(ij_permutations[:1], position=0):\n",
    "    local_dist_errors = []\n",
    "    local_angle_errors = []\n",
    "    database = TRACK_LIST[i]\n",
    "    query = TRACK_LIST[j]\n",
    "    cfg = compose(\"train_soc.yaml\", overrides=[f\"dataset.dataset_root=/home/docker_opr/Datasets/MIPT_campus/indoor/{TRACK_LIST[j]}\"])\n",
    "\n",
    "    pipeline = PlaceRecognitionPipeline(\n",
    "        database_dir=f\"/home/docker_opr/Datasets/MIPT_campus/indoor/databases/{database}_or\",\n",
    "        model=instantiate(cfg.model),\n",
    "        model_weights_path=WEIGHTS_PATH,\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "\n",
    "    query_dataset = instantiate(cfg.dataset, subset=\"test\", csv_file=\"track.csv\")\n",
    "\n",
    "    for sample in tqdm(query_dataset, position=1):\n",
    "        start_time = time()\n",
    "        out = pipeline.infer(sample)\n",
    "        times.append(time() - start_time)\n",
    "        \n",
    "        dist_error, angle_error = compute_error(sample[\"pose\"].numpy(), out[\"pose\"])\n",
    "        local_dist_errors.append(dist_error)\n",
    "        local_angle_errors.append(angle_error)\n",
    "        estimated_pose = pose_to_matrix(out[\"pose\"])\n",
    "        gt_pose = pose_to_matrix(sample[\"pose\"].numpy())\n",
    "        _, db_match_distance = compute_registration_error(gt_pose, estimated_pose)\n",
    "        pr_matched = db_match_distance <= PR_MATCH_THRESHOLD\n",
    "        pr_matches.append(pr_matched)\n",
    "\n",
    "\n",
    "    median_dist_errors.append(np.median(local_dist_errors))\n",
    "    median_angle_errors.append(np.median(local_angle_errors))\n",
    "    mean_dist_errors.append(np.mean(local_dist_errors))\n",
    "    mean_angle_errors.append(np.mean(local_angle_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PlaceRecognition R@1 = {np.mean(pr_matches):0.3f}\")\n",
    "\n",
    "print(f\"Mean Time = {(np.mean(times) * 1000):0.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_dist_errors, mean_dist_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_angle_errors, mean_angle_errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
