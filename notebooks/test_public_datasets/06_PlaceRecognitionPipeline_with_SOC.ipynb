{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PlaceRecognitionPipeline with SOC\n",
    "\n",
    "A module that implements a neural network algorithm for searching a database of places already visited by a vehicle for the most similar records using data from lidars and cameras and highlighting special elements of a three-dimensional scene (doors, buildings, street signs, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_769955/507557485.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "import faiss\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hydra.utils import instantiate\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "from scipy.spatial.transform import Rotation\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from opr.datasets import NCLTDataset\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return dist_error, angle_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/docker_opr/Datasets/NCLT_preprocessed\"\n",
    "SEMANTIC_ANNO = \"/home/docker_opr/OpenPlaceRecognition/configs/dataset/anno/oneformer.yaml\"\n",
    "\n",
    "SENSOR_SUITE = [\"image_Cam5\", \"image_Cam2\", \"mask_Cam5\", \"pointcloud_lidar\"]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_lidar_late-fusion_nclt.pth\"\n",
    "SOC_WEIGHTS_PATH = \"../../weights/place_recognition/soc_nclt.pth\"\n",
    "SOC_CONFIG_PATH = \"../../configs/model/place_recognition/soc_mixer.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 tracks\n",
      "['2012-01-08', '2012-01-22', '2012-02-12', '2012-02-18', '2012-03-31', '2012-05-26', '2012-08-04', '2012-10-28', '2012-11-04', '2012-12-01']\n",
      "WARNING: track list limited\n",
      "['2012-01-08', '2012-01-22']\n"
     ]
    }
   ],
   "source": [
    "TRACK_LIST = sorted([str(subdir.name) for subdir in Path(DATASET_ROOT).iterdir() if subdir.is_dir()])\n",
    "print(f\"Found {len(TRACK_LIST)} tracks\")\n",
    "print(TRACK_LIST)\n",
    "print(\"WARNING: track list limited\")\n",
    "TRACK_LIST = TRACK_LIST[:2]\n",
    "print(TRACK_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_config = OmegaConf.load(SOC_CONFIG_PATH)\n",
    "soc_model = instantiate(soc_config)\n",
    "soc_model.load_state_dict(torch.load(SOC_WEIGHTS_PATH)[\"model_state_dict\"])\n",
    "model_config = OmegaConf.load(MODEL_CONFIG_PATH)\n",
    "model = instantiate(model_config)\n",
    "model.load_state_dict(torch.load(WEIGHTS_PATH))\n",
    "model.soc_module = soc_model\n",
    "model = model.to(DEVICE)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate descriptors for databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_anno_cfg = OmegaConf.load(SEMANTIC_ANNO)\n",
    "dataset = NCLTDataset(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    data_to_load=SENSOR_SUITE,\n",
    "    pointcloud_quantization_size=0.5,\n",
    "    max_point_distance=None,\n",
    "    load_soc=True,\n",
    "    anno=semantic_anno_cfg,\n",
    "    top_k_soc=5,\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=dataset.collate_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [02:06<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        final_descriptor = model(batch)[\"final_descriptor\"]\n",
    "        descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "\n",
    "descriptors = np.concatenate(descriptors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-01-08/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-01-22/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-02-12/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-02-18/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-03-31/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-05-26/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-08-04/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-10-28/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-11-04/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-12-01/index.faiss\n"
     ]
    }
   ],
   "source": [
    "dataset_df = dataset.dataset_df\n",
    "\n",
    "for track, indices in dataset_df.groupby(\"track\").groups.items():\n",
    "    track_descriptors = descriptors[indices]\n",
    "    track_index = faiss.IndexFlatL2(track_descriptors.shape[1])\n",
    "    track_index.add(track_descriptors)\n",
    "    faiss.write_index(track_index, f\"{DATASET_ROOT}/{track}/index.faiss\")\n",
    "    print(f\"Saved index {DATASET_ROOT}/{track}/index.faiss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [00:30,  8.92it/s]\n",
      "331it [00:37,  8.78it/s]\n"
     ]
    }
   ],
   "source": [
    "PR_THRESHOLD = 25.0\n",
    "\n",
    "test_csv = pd.read_csv(Path(DATASET_ROOT) / \"test.csv\", index_col=0)\n",
    "\n",
    "all_recalls = []\n",
    "all_mean_dist_errors = []\n",
    "all_mean_angle_errors = []\n",
    "all_median_dist_errors = []\n",
    "all_median_angle_errors = []\n",
    "all_times = []\n",
    "\n",
    "for db_track in TRACK_LIST:\n",
    "    pipe = PlaceRecognitionPipeline(\n",
    "        database_dir=Path(DATASET_ROOT) / db_track,\n",
    "        model=model,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    for query_track in TRACK_LIST:\n",
    "        if db_track == query_track:\n",
    "            continue\n",
    "        query_dataset = copy(dataset)\n",
    "        query_dataset.dataset_df = query_dataset.dataset_df[query_dataset.dataset_df[\"track\"] == query_track]\n",
    "        query_df = pd.read_csv(Path(DATASET_ROOT) / query_track / \"track.csv\", index_col=0)\n",
    "\n",
    "        # filter out only test subset\n",
    "        query_df = query_df[query_df['image'].isin(query_dataset.dataset_df['image'])].reset_index(drop=True)\n",
    "        # and do not forget to change the database_df in the pipeline\n",
    "        pipe.database_df = pipe.database_df[pipe.database_df['image'].isin(test_csv['image'])].reset_index(drop=True)\n",
    "\n",
    "        pr_matches = []\n",
    "        dist_errors = []\n",
    "        angle_errors = []\n",
    "        times = []\n",
    "\n",
    "        true_pairs = []\n",
    "        false_pairs = []\n",
    "\n",
    "        for q_i, query in tqdm(enumerate(query_dataset)):\n",
    "            query[\"pose\"] = query_df.iloc[q_i][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "            t = time()\n",
    "            output = pipe.infer(query)\n",
    "            times.append(time() - t)\n",
    "            dist_error, angle_error = compute_error(output[\"pose\"], query[\"pose\"])\n",
    "            pr_matches.append(dist_error < PR_THRESHOLD)\n",
    "            dist_errors.append(dist_error)\n",
    "            angle_errors.append(angle_error)\n",
    "            if dist_error < 10:\n",
    "                true_pairs.append((q_i, output[\"idx\"]))\n",
    "            elif dist_error > 100:\n",
    "                false_pairs.append((q_i, output[\"idx\"]))\n",
    "\n",
    "        all_recalls.append(np.mean(pr_matches))\n",
    "        all_mean_dist_errors.append(np.mean(dist_errors))\n",
    "        all_mean_angle_errors.append(np.mean(angle_errors))\n",
    "        all_median_dist_errors.append(np.median(dist_errors))\n",
    "        all_median_angle_errors.append(np.median(angle_errors))\n",
    "        all_times.extend(times[1:]) # drop the first iteration cause it is always slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928025267783576"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_recalls).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.217167697169343"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_mean_dist_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.470159108054585"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_median_dist_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_str = f\"\"\"Average Recall@1: {np.mean(all_recalls)*100:.2f}\n",
    "Average mean dist error: {np.mean(all_mean_dist_errors):.2f}\n",
    "Average mean angle error: {np.mean(all_mean_angle_errors):.2f}\n",
    "Average median dist error: {np.mean(all_median_dist_errors):.2f}\n",
    "Average median angle error: {np.mean(all_median_angle_errors):.2f}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall@1: 92.80\n",
      "Average mean dist error: 12.22\n",
      "Average mean angle error: 11.51\n",
      "Average median dist error: 4.47\n",
      "Average median angle error: 6.65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
