{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PlaceRecognitionPipeline - NCLT dataset test\n",
    "\n",
    "A module that implements a neural network algorithm for searching a database of places already visited by a vehicle for the most similar records using sequences of data from lidars and cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30180/500884647.py:15: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import faiss\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from hydra.utils import instantiate\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "from scipy.spatial.transform import Rotation\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "from opr.datasets import NCLTDataset\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return dist_error, angle_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the dataset:\n",
    "\n",
    "- Kaggle:\n",
    "  - [NCLT_OpenPlaceRecognition](https://www.kaggle.com/datasets/creatorofuniverses/nclt-iprofi-hack-23)\n",
    "- Hugging Face:\n",
    "  - [NCLT_OpenPlaceRecognition](https://huggingface.co/datasets/OPR-Project/NCLT_OpenPlaceRecognition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/docker_opr/Datasets/NCLT_preprocessed\"\n",
    "\n",
    "SENSOR_SUITE = [\"image_Cam5\", \"image_Cam2\", \"pointcloud_lidar\"]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_lidar_late-fusion_nclt.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 tracks\n",
      "['2012-01-08', '2012-01-22', '2012-02-12', '2012-02-18', '2012-03-31', '2012-05-26', '2012-08-04', '2012-10-28', '2012-11-04', '2012-12-01']\n",
      "WARNING: track list limited\n",
      "['2012-01-08', '2012-01-22']\n"
     ]
    }
   ],
   "source": [
    "TRACK_LIST = sorted([str(subdir.name) for subdir in Path(DATASET_ROOT).iterdir() if subdir.is_dir()])\n",
    "print(f\"Found {len(TRACK_LIST)} tracks\")\n",
    "print(TRACK_LIST)\n",
    "\n",
    "print(\"WARNING: track list limited\")\n",
    "TRACK_LIST = TRACK_LIST[:2]\n",
    "print(TRACK_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/docker_opr/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:04<00:00, 10.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_config = OmegaConf.load(MODEL_CONFIG_PATH)\n",
    "model = instantiate(model_config)\n",
    "model.load_state_dict(torch.load(WEIGHTS_PATH))\n",
    "model = model.to(DEVICE)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate descriptors for databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NCLTDataset(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    data_to_load=SENSOR_SUITE,\n",
    "    pointcloud_quantization_size=0.5,\n",
    "    max_point_distance=None,\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=dataset.collate_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:17<00:00,  4.97it/s]\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        final_descriptor = model(batch)[\"final_descriptor\"]\n",
    "        descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "\n",
    "descriptors = np.concatenate(descriptors, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving database indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-01-08/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-01-22/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-02-12/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-02-18/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-03-31/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-05-26/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-08-04/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-10-28/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-11-04/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-12-01/index.faiss\n"
     ]
    }
   ],
   "source": [
    "dataset_df = dataset.dataset_df\n",
    "\n",
    "for track, indices in dataset_df.groupby(\"track\").groups.items():\n",
    "    track_descriptors = descriptors[indices]\n",
    "    track_index = faiss.IndexFlatL2(track_descriptors.shape[1])\n",
    "    track_index.add(track_descriptors)\n",
    "    faiss.write_index(track_index, f\"{DATASET_ROOT}/{track}/index.faiss\")\n",
    "    print(f\"Saved index {DATASET_ROOT}/{track}/index.faiss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>image</th>\n",
       "      <th>pointcloud</th>\n",
       "      <th>northing</th>\n",
       "      <th>easting</th>\n",
       "      <th>down</th>\n",
       "      <th>r</th>\n",
       "      <th>p</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1326031198728706</td>\n",
       "      <td>1326031198730853</td>\n",
       "      <td>1326031198730853</td>\n",
       "      <td>-48.332952</td>\n",
       "      <td>-205.678453</td>\n",
       "      <td>3.517986</td>\n",
       "      <td>-0.046535</td>\n",
       "      <td>-0.072653</td>\n",
       "      <td>-1.384030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1326031208333823</td>\n",
       "      <td>1326031208331035</td>\n",
       "      <td>1326031208331035</td>\n",
       "      <td>-45.950548</td>\n",
       "      <td>-215.383738</td>\n",
       "      <td>3.523764</td>\n",
       "      <td>0.008058</td>\n",
       "      <td>-0.059990</td>\n",
       "      <td>-1.344043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1326031215134679</td>\n",
       "      <td>1326031215131176</td>\n",
       "      <td>1326031215131176</td>\n",
       "      <td>-45.543845</td>\n",
       "      <td>-225.309474</td>\n",
       "      <td>4.635879</td>\n",
       "      <td>-0.021489</td>\n",
       "      <td>0.135795</td>\n",
       "      <td>-1.625108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1326031222333459</td>\n",
       "      <td>1326031222331359</td>\n",
       "      <td>1326031222331359</td>\n",
       "      <td>-46.472043</td>\n",
       "      <td>-235.262145</td>\n",
       "      <td>5.880303</td>\n",
       "      <td>-0.047618</td>\n",
       "      <td>0.131018</td>\n",
       "      <td>-1.669638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1326031229934828</td>\n",
       "      <td>1326031229931488</td>\n",
       "      <td>1326031229931488</td>\n",
       "      <td>-47.415861</td>\n",
       "      <td>-245.140641</td>\n",
       "      <td>6.817459</td>\n",
       "      <td>-0.038579</td>\n",
       "      <td>-0.010276</td>\n",
       "      <td>-1.546032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp             image        pointcloud   northing  \\\n",
       "0  1326031198728706  1326031198730853  1326031198730853 -48.332952   \n",
       "1  1326031208333823  1326031208331035  1326031208331035 -45.950548   \n",
       "2  1326031215134679  1326031215131176  1326031215131176 -45.543845   \n",
       "3  1326031222333459  1326031222331359  1326031222331359 -46.472043   \n",
       "4  1326031229934828  1326031229931488  1326031229931488 -47.415861   \n",
       "\n",
       "      easting      down         r         p         h  \n",
       "0 -205.678453  3.517986 -0.046535 -0.072653 -1.384030  \n",
       "1 -215.383738  3.523764  0.008058 -0.059990 -1.344043  \n",
       "2 -225.309474  4.635879 -0.021489  0.135795 -1.625108  \n",
       "3 -235.262145  5.880303 -0.047618  0.131018 -1.669638  \n",
       "4 -245.140641  6.817459 -0.038579 -0.010276 -1.546032  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.database_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [00:49,  5.50it/s]\n",
      "331it [00:58,  5.61it/s]\n"
     ]
    }
   ],
   "source": [
    "PR_THRESHOLD = 25.0\n",
    "\n",
    "test_csv = pd.read_csv(Path(DATASET_ROOT) / \"test.csv\", index_col=0)\n",
    "\n",
    "all_recalls = []\n",
    "all_mean_dist_errors = []\n",
    "all_mean_angle_errors = []\n",
    "all_median_dist_errors = []\n",
    "all_median_angle_errors = []\n",
    "all_times = []\n",
    "\n",
    "for db_track in TRACK_LIST:\n",
    "    pipe = PlaceRecognitionPipeline(\n",
    "        database_dir=Path(DATASET_ROOT) / db_track,\n",
    "        model=model,\n",
    "        model_weights_path=WEIGHTS_PATH,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    for query_track in TRACK_LIST:\n",
    "        if db_track == query_track:\n",
    "            continue\n",
    "        query_dataset = copy(dataset)\n",
    "        query_dataset.dataset_df = query_dataset.dataset_df[query_dataset.dataset_df[\"track\"] == query_track]\n",
    "        query_df = pd.read_csv(Path(DATASET_ROOT) / query_track / \"track.csv\", index_col=0)\n",
    "\n",
    "        # filter out only test subset\n",
    "        query_df = query_df[query_df['image'].isin(query_dataset.dataset_df['image'])].reset_index(drop=True)\n",
    "        # and do not forget to change the database_df in the pipeline\n",
    "        pipe.database_df = pipe.database_df[pipe.database_df['image'].isin(test_csv['image'])].reset_index(drop=True)\n",
    "\n",
    "        pr_matches = []\n",
    "        dist_errors = []\n",
    "        angle_errors = []\n",
    "        times = []\n",
    "\n",
    "        true_pairs = []\n",
    "        false_pairs = []\n",
    "\n",
    "        for q_i, query in tqdm(enumerate(query_dataset)):\n",
    "            query[\"pose\"] = query_df.iloc[q_i][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "            t = time()\n",
    "            output = pipe.infer(query)\n",
    "            times.append(time() - t)\n",
    "            dist_error, angle_error = compute_error(output[\"pose\"], query[\"pose\"])\n",
    "            pr_matches.append(dist_error < PR_THRESHOLD)\n",
    "            dist_errors.append(dist_error)\n",
    "            angle_errors.append(angle_error)\n",
    "            if dist_error < 10:\n",
    "                true_pairs.append((q_i, output[\"idx\"]))\n",
    "            elif dist_error > 100:\n",
    "                false_pairs.append((q_i, output[\"idx\"]))\n",
    "\n",
    "        all_recalls.append(np.mean(pr_matches))\n",
    "        all_mean_dist_errors.append(np.mean(dist_errors))\n",
    "        all_mean_angle_errors.append(np.mean(angle_errors))\n",
    "        all_median_dist_errors.append(np.median(dist_errors))\n",
    "        all_median_angle_errors.append(np.median(angle_errors))\n",
    "        all_times.extend(times[1:]) # drop the first iteration cause it is always slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928025267783576"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_recalls).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.217167697169343"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_mean_dist_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.470159108054585"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_median_dist_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_str = f\"\"\"Average Recall@1: {np.mean(all_recalls)*100:.2f}\n",
    "Average mean dist error: {np.mean(all_mean_dist_errors):.2f}\n",
    "Average mean angle error: {np.mean(all_mean_angle_errors):.2f}\n",
    "Average median dist error: {np.mean(all_median_dist_errors):.2f}\n",
    "Average median angle error: {np.mean(all_median_angle_errors):.2f}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall@1: 92.80\n",
      "Average mean dist error: 12.22\n",
      "Average mean angle error: 11.51\n",
      "Average median dist error: 4.47\n",
      "Average median angle error: 6.65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
