{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SequencePointcloudRegistrationPipeline\n",
    "\n",
    "A module that implements an algorithm for optimizing the position and orientation of a vehicle in space based on a sequence of multimodal data using neural network methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from copy import copy\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import faiss\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from hydra.utils import instantiate\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "from scipy.spatial.transform import Rotation\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "try:\n",
    "    from geotransformer.utils.registration import compute_registration_error\n",
    "    from geotransformer.utils.pointcloud import get_transform_from_rotation_translation\n",
    "except ImportError:\n",
    "    print(\"WARNING: geotransformer not installed, registration error will not be computed\")\n",
    "\n",
    "from opr.datasets import NCLTDataset\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline\n",
    "from opr.pipelines.registration.pointcloud import SequencePointcloudRegistrationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return dist_error, angle_error\n",
    "\n",
    "def compute_translation_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    gt_trans = gt_pose[:3, 3]\n",
    "    pred_trans = pred_pose[:3, 3]\n",
    "    error = np.linalg.norm(gt_trans - pred_trans)\n",
    "    return error\n",
    "\n",
    "def compute_rotation_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    gt_rot = Rotation.from_matrix(gt_pose[:3, :3])\n",
    "    pred_rot = Rotation.from_matrix(pred_pose[:3, :3])\n",
    "    error = Rotation.inv(gt_rot) * pred_rot\n",
    "    error = error.as_euler('xyz', degrees=True)\n",
    "    error = np.linalg.norm(error)\n",
    "    return error\n",
    "\n",
    "def compute_absolute_pose_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    rotation_error = compute_rotation_error(gt_pose, pred_pose)\n",
    "    translation_error = compute_translation_error(gt_pose, pred_pose)\n",
    "    return rotation_error, translation_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can **download the dataset**:\n",
    "\n",
    "- Kaggle:\n",
    "  - [NCLT_OpenPlaceRecognition](https://www.kaggle.com/datasets/creatorofuniverses/nclt-iprofi-hack-23)\n",
    "- Hugging Face:\n",
    "  - [NCLT_OpenPlaceRecognition](https://huggingface.co/datasets/OPR-Project/NCLT_OpenPlaceRecognition)\n",
    "\n",
    "To **download the model weights**, run the following command:\n",
    "\n",
    "```bash\n",
    "# place recognition weights\n",
    "wget -O ../../weights/place_recognition/multi-image_lidar_late-fusion_nclt.pth https://huggingface.co/OPR-Project/PlaceRecognition-NCLT/resolve/main/multi-image_lidar_late-fusion_nclt.pth\n",
    "\n",
    "# registration weights\n",
    "wget -O ../../weights/registration/geotransformer_kitti.pth https://huggingface.co/OPR-Project/Registration-KITTI/resolve/main/geotransformer_kitti.pth\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-18 12:35:02--  https://huggingface.co/OPR-Project/PlaceRecognition-NCLT/resolve/main/multi-image_lidar_late-fusion_nclt.pth\n",
      "Resolving huggingface.co (huggingface.co)... 18.239.50.49, 18.239.50.103, 18.239.50.16, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.239.50.49|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.hf.co/repos/e8/30/e8306844a097b119f688c0cfcf564a9f584f52c28b0d3c5b11e560cb0c3e7eeb/db4f7efcbaf0acd445381074b1a78fba7c9e0972e7996994ed9db95fd4e0a243?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27multi-image_lidar_late-fusion_nclt.pth%3B+filename%3D%22multi-image_lidar_late-fusion_nclt.pth%22%3B&Expires=1744983302&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDk4MzMwMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U4LzMwL2U4MzA2ODQ0YTA5N2IxMTlmNjg4YzBjZmNmNTY0YTlmNTg0ZjUyYzI4YjBkM2M1YjExZTU2MGNiMGMzZTdlZWIvZGI0ZjdlZmNiYWYwYWNkNDQ1MzgxMDc0YjFhNzhmYmE3YzllMDk3MmU3OTk2OTk0ZWQ5ZGI5NWZkNGUwYTI0Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=HJAnaaFmftm3cNW6opsKaXkUyxFdEoinnUEXZtsajr3j4P4I97ipwZDL-6Dw2s17Cx8BVJg-ZBYFLN%7EaNkYSj-x0BWI19mTljxXsKwkKEPuZq5%7EBAo6FZT7XyrG0m3iNVoaD0vSLV-duIs84EOcNjjS31DJ1coUTvuM-rgsDyd67ayl6ywBmM0gSEkZV%7EXf7zbyej4VqOHlptFkSvY8IVMuNkQDF9MxWEInhaFz0j2oqy576aBnrZz-Pe0jYZs03P4XW4rTUw6JwLMTemAvItXgt9E3IweiDCVHIysmw0NbRSmU1BhcVmONPG2u67rYT8kJmqRC%7ELzN68AMw9a6tWA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
      "--2025-04-18 12:35:02--  https://cdn-lfs-us-1.hf.co/repos/e8/30/e8306844a097b119f688c0cfcf564a9f584f52c28b0d3c5b11e560cb0c3e7eeb/db4f7efcbaf0acd445381074b1a78fba7c9e0972e7996994ed9db95fd4e0a243?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27multi-image_lidar_late-fusion_nclt.pth%3B+filename%3D%22multi-image_lidar_late-fusion_nclt.pth%22%3B&Expires=1744983302&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDk4MzMwMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2U4LzMwL2U4MzA2ODQ0YTA5N2IxMTlmNjg4YzBjZmNmNTY0YTlmNTg0ZjUyYzI4YjBkM2M1YjExZTU2MGNiMGMzZTdlZWIvZGI0ZjdlZmNiYWYwYWNkNDQ1MzgxMDc0YjFhNzhmYmE3YzllMDk3MmU3OTk2OTk0ZWQ5ZGI5NWZkNGUwYTI0Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=HJAnaaFmftm3cNW6opsKaXkUyxFdEoinnUEXZtsajr3j4P4I97ipwZDL-6Dw2s17Cx8BVJg-ZBYFLN%7EaNkYSj-x0BWI19mTljxXsKwkKEPuZq5%7EBAo6FZT7XyrG0m3iNVoaD0vSLV-duIs84EOcNjjS31DJ1coUTvuM-rgsDyd67ayl6ywBmM0gSEkZV%7EXf7zbyej4VqOHlptFkSvY8IVMuNkQDF9MxWEInhaFz0j2oqy576aBnrZz-Pe0jYZs03P4XW4rTUw6JwLMTemAvItXgt9E3IweiDCVHIysmw0NbRSmU1BhcVmONPG2u67rYT8kJmqRC%7ELzN68AMw9a6tWA__&Key-Pair-Id=K24J24Z295AEI9\n",
      "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 65.9.86.113, 65.9.86.32, 65.9.86.128, ...\n",
      "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|65.9.86.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22148979 (21M) [binary/octet-stream]\n",
      "Saving to: ‘../../weights/place_recognition/multi-image_lidar_late-fusion_nclt.pth’\n",
      "\n",
      "../../weights/place 100%[===================>]  21.12M  4.64MB/s    in 4.4s    \n",
      "\n",
      "2025-04-18 12:35:07 (4.77 MB/s) - ‘../../weights/place_recognition/multi-image_lidar_late-fusion_nclt.pth’ saved [22148979/22148979]\n",
      "\n",
      "--2025-04-18 12:35:07--  https://huggingface.co/OPR-Project/Registration-KITTI/resolve/main/geotransformer_kitti.pth\n",
      "Resolving huggingface.co (huggingface.co)... 18.239.50.49, 18.239.50.103, 18.239.50.16, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.239.50.49|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.hf.co/repos/4f/3d/4f3d64f4dec115c07c1a9eb9d7a340e387901885895835e0f1d44afac6ef9073/677efe25f76cb43f99f9d74748e1f7ed028251fac8d9e69e6431031fc1835445?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27geotransformer_kitti.pth%3B+filename%3D%22geotransformer_kitti.pth%22%3B&Expires=1744983307&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDk4MzMwN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzNkLzRmM2Q2NGY0ZGVjMTE1YzA3YzFhOWViOWQ3YTM0MGUzODc5MDE4ODU4OTU4MzVlMGYxZDQ0YWZhYzZlZjkwNzMvNjc3ZWZlMjVmNzZjYjQzZjk5ZjlkNzQ3NDhlMWY3ZWQwMjgyNTFmYWM4ZDllNjllNjQzMTAzMWZjMTgzNTQ0NT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=kPbBjV7pONv57jFkcyfo6PZo4sz6tbb%7ExU1xto%7EnmgqxcTpz79LkCR5okZhE0kGDJPBirIUx7ya%7EISbkBk46xaDC72ACDfNGXqfNQ0kiiUEQODnqB95po5clxZmili-hL9-5bgcHzMLAuIY1kpkfUjMkBLu%7EfcfKIQ8%7EjWFmUc4MznvlHX3NbM7vPjYgdFsVOBAFZFr1TladON3%7EXGmADNOOZXmbrEndfmtm2InGAp891o2rWYLg%7EryxA1NP3M6pgvB-HnV9TVNI1eTcfsDMuDNZCMUbsxgbnjCQPv8V5nTdLcb8GRTtdBqWflHsXO334LphafccOWvaRVtO-iRY3w__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
      "--2025-04-18 12:35:07--  https://cdn-lfs-us-1.hf.co/repos/4f/3d/4f3d64f4dec115c07c1a9eb9d7a340e387901885895835e0f1d44afac6ef9073/677efe25f76cb43f99f9d74748e1f7ed028251fac8d9e69e6431031fc1835445?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27geotransformer_kitti.pth%3B+filename%3D%22geotransformer_kitti.pth%22%3B&Expires=1744983307&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDk4MzMwN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRmLzNkLzRmM2Q2NGY0ZGVjMTE1YzA3YzFhOWViOWQ3YTM0MGUzODc5MDE4ODU4OTU4MzVlMGYxZDQ0YWZhYzZlZjkwNzMvNjc3ZWZlMjVmNzZjYjQzZjk5ZjlkNzQ3NDhlMWY3ZWQwMjgyNTFmYWM4ZDllNjllNjQzMTAzMWZjMTgzNTQ0NT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=kPbBjV7pONv57jFkcyfo6PZo4sz6tbb%7ExU1xto%7EnmgqxcTpz79LkCR5okZhE0kGDJPBirIUx7ya%7EISbkBk46xaDC72ACDfNGXqfNQ0kiiUEQODnqB95po5clxZmili-hL9-5bgcHzMLAuIY1kpkfUjMkBLu%7EfcfKIQ8%7EjWFmUc4MznvlHX3NbM7vPjYgdFsVOBAFZFr1TladON3%7EXGmADNOOZXmbrEndfmtm2InGAp891o2rWYLg%7EryxA1NP3M6pgvB-HnV9TVNI1eTcfsDMuDNZCMUbsxgbnjCQPv8V5nTdLcb8GRTtdBqWflHsXO334LphafccOWvaRVtO-iRY3w__&Key-Pair-Id=K24J24Z295AEI9\n",
      "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 65.9.86.113, 65.9.86.32, 65.9.86.128, ...\n",
      "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|65.9.86.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 102123209 (97M) [binary/octet-stream]\n",
      "Saving to: ‘../../weights/registration/geotransformer_kitti.pth’\n",
      "\n",
      "../../weights/regis 100%[===================>]  97.39M  4.58MB/s    in 21s     \n",
      "\n",
      "2025-04-18 12:35:29 (4.65 MB/s) - ‘../../weights/registration/geotransformer_kitti.pth’ saved [102123209/102123209]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# place recognition weights\n",
    "!wget -O ../../weights/place_recognition/multi-image_lidar_late-fusion_nclt.pth https://huggingface.co/OPR-Project/PlaceRecognition-NCLT/resolve/main/multi-image_lidar_late-fusion_nclt.pth\n",
    "\n",
    "# registration weights\n",
    "!wget -O ../../weights/registration/geotransformer_kitti.pth https://huggingface.co/OPR-Project/Registration-KITTI/resolve/main/geotransformer_kitti.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed\"  # change to your dataset path\n",
    "\n",
    "SENSOR_SUITE = [\"image_Cam5\", \"image_Cam2\", \"mask_Cam5\", \"mask_Cam2\", \"pointcloud_lidar\"]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "REGISTRATION_MODEL_CONFIG_PATH = \"../../configs/model/registration/geotransformer_kitti.yaml\"\n",
    "REGISTRATION_WEIGHTS_PATH = \"../../weights/registration/geotransformer_kitti.pth\"\n",
    "\n",
    "MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_lidar_late-fusion_nclt.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 tracks\n",
      "['2012-01-08', '2012-01-22', '2012-02-12', '2012-02-18', '2012-03-31', '2012-05-26', '2012-08-04', '2012-10-28', '2012-11-04', '2012-12-01']\n",
      "WARNING: track list limited\n",
      "['2012-01-08', '2012-01-22']\n"
     ]
    }
   ],
   "source": [
    "TRACK_LIST = sorted([str(subdir.name) for subdir in Path(DATASET_ROOT).iterdir() if subdir.is_dir()])\n",
    "print(f\"Found {len(TRACK_LIST)} tracks\")\n",
    "print(TRACK_LIST)\n",
    "\n",
    "print(\"WARNING: track list limited\")\n",
    "TRACK_LIST = TRACK_LIST[:2]\n",
    "print(TRACK_LIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-18 12:35:55.507\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mopr.models.place_recognition.pointmamba\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[33m\u001b[1mThe 'pointmamba' package is not installed. Please install it manually if neccessary.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_config = OmegaConf.load(MODEL_CONFIG_PATH)\n",
    "model = instantiate(model_config)\n",
    "model.load_state_dict(torch.load(WEIGHTS_PATH))\n",
    "model = model.to(DEVICE)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate descriptors for databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NCLTDataset(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    data_to_load=SENSOR_SUITE,\n",
    "    pointcloud_quantization_size=0.5,\n",
    "    max_point_distance=None,\n",
    "    exclude_dynamic=True,\n",
    "    dynamic_labels=[19] #Person\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=dataset.collate_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/86 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [01:02<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        final_descriptor = model(batch)[\"final_descriptor\"]\n",
    "        descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "\n",
    "descriptors = np.concatenate(descriptors, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving database indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed/2012-01-08/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed/2012-01-22/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed/2012-02-12/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed/2012-02-18/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed/2012-03-31/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed/2012-05-26/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed/2012-08-04/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed/2012-10-28/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed/2012-11-04/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/NCLT_preprocessed/2012-12-01/index.faiss\n"
     ]
    }
   ],
   "source": [
    "dataset_df = dataset.dataset_df\n",
    "\n",
    "for track, indices in dataset_df.groupby(\"track\").groups.items():\n",
    "    track_descriptors = descriptors[indices]\n",
    "    track_index = faiss.IndexFlatL2(track_descriptors.shape[1])\n",
    "    track_index.add(track_descriptors)\n",
    "    faiss.write_index(track_index, f\"{DATASET_ROOT}/{track}/index.faiss\")\n",
    "    print(f\"Saved index {DATASET_ROOT}/{track}/index.faiss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init GeoTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotransformer = instantiate(OmegaConf.load(REGISTRATION_MODEL_CONFIG_PATH))\n",
    "\n",
    "registration_pipe = SequencePointcloudRegistrationPipeline(\n",
    "    model=geotransformer,\n",
    "    model_weights_path=REGISTRATION_WEIGHTS_PATH,\n",
    "    device=\"cuda\",  # the GeoTransformer currently only supports CUDA\n",
    "    voxel_downsample_size=0.5,  # recommended for geotransformer_kitti configuration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [00:26<00:00, 10.16it/s]\n",
      "100%|██████████| 274/274 [04:50<00:00,  1.06s/it]\n",
      "100%|██████████| 330/330 [00:34<00:00,  9.51it/s]\n",
      "100%|██████████| 330/330 [05:31<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "PR_THRESHOLD = 25.0\n",
    "\n",
    "test_csv = pd.read_csv(Path(DATASET_ROOT) / \"test.csv\", index_col=0)\n",
    "\n",
    "all_recalls = []\n",
    "all_mean_dist_errors = []\n",
    "all_mean_angle_errors = []\n",
    "all_median_dist_errors = []\n",
    "all_median_angle_errors = []\n",
    "all_times = []\n",
    "\n",
    "for db_track in TRACK_LIST:\n",
    "    pipe = PlaceRecognitionPipeline(\n",
    "        database_dir=Path(DATASET_ROOT) / db_track,\n",
    "        model=model,\n",
    "        model_weights_path=WEIGHTS_PATH,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    for query_track in TRACK_LIST:\n",
    "        if db_track == query_track:\n",
    "            continue\n",
    "        query_dataset = copy(dataset)\n",
    "        query_dataset.dataset_df = query_dataset.dataset_df[query_dataset.dataset_df[\"track\"] == query_track]\n",
    "        db_dataset = copy(dataset)\n",
    "        db_dataset.dataset_df = db_dataset.dataset_df[db_dataset.dataset_df[\"track\"] == db_track]\n",
    "        query_df = pd.read_csv(Path(DATASET_ROOT) / query_track / \"track.csv\", index_col=0)\n",
    "\n",
    "        # filter out only test subset\n",
    "        query_df = query_df[query_df['image'].isin(query_dataset.dataset_df['image'])].reset_index(drop=True)\n",
    "        # and do not forget to change the database_df in the pipeline\n",
    "        pipe.database_df = pipe.database_df[pipe.database_df['image'].isin(test_csv['image'])].reset_index(drop=True)\n",
    "\n",
    "        pr_matches = []\n",
    "        dist_errors = []\n",
    "        angle_errors = []\n",
    "        times = []\n",
    "\n",
    "        true_pairs = []\n",
    "        false_pairs = []\n",
    "\n",
    "        # STAGE 1 - place recognition\n",
    "        db_matches = {}\n",
    "        for q_i in tqdm(range(1, len(query_dataset)), total=len(query_dataset)-1):\n",
    "            query = query_dataset[q_i]\n",
    "            query[\"pose\"] = query_df.iloc[q_i][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "            output = pipe.infer(query)\n",
    "            db_matches[q_i] = output[\"idx\"]\n",
    "        torch.cuda.empty_cache()\n",
    "        # STAGE 2 - registration\n",
    "        for q_i in tqdm(range(1, len(query_dataset)), total=len(query_dataset)-1):\n",
    "            query = query_dataset[q_i]\n",
    "            query_seq = [query_dataset[q_i][\"pointcloud_lidar_coords\"]]\n",
    "            output_idx = db_matches[q_i]\n",
    "            db_match = db_dataset[output_idx]\n",
    "            torch.cuda.empty_cache()\n",
    "            db_match[\"pose\"] = pipe.database_df.iloc[output_idx][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "            db_pose = pose_to_matrix(db_match[\"pose\"])\n",
    "            db_pc = db_match[\"pointcloud_lidar_coords\"]\n",
    "            t = time()\n",
    "            estimated_transformation = registration_pipe.infer(query_seq, db_pc)\n",
    "            times.append(time() - t)\n",
    "            optimized_pose = db_pose @ estimated_transformation\n",
    "            torch.cuda.empty_cache()\n",
    "            query[\"pose\"] = query_df.iloc[q_i][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "            angle_error, dist_error = compute_absolute_pose_error(optimized_pose, pose_to_matrix(query[\"pose\"]))\n",
    "\n",
    "            pr_matches.append(dist_error < PR_THRESHOLD)\n",
    "            dist_errors.append(dist_error)\n",
    "            angle_errors.append(angle_error)\n",
    "\n",
    "        all_recalls.append(np.mean(pr_matches))\n",
    "        all_mean_dist_errors.append(np.mean(dist_errors))\n",
    "        all_mean_angle_errors.append(np.mean(angle_errors))\n",
    "        all_median_dist_errors.append(np.median(dist_errors))\n",
    "        all_median_angle_errors.append(np.median(angle_errors))\n",
    "        all_times.extend(times[1:]) # drop the first iteration cause it is always slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_str = f\"\"\"Average Recall@1: {np.mean(all_recalls)*100:.2f}\n",
    "Average mean dist error: {np.mean(all_mean_dist_errors):.2f}\n",
    "Average mean angle error: {np.mean(all_mean_angle_errors):.2f}\n",
    "Average median dist error: {np.mean(all_median_dist_errors):.2f}\n",
    "Average median angle error: {np.mean(all_median_angle_errors):.2f}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall@1: 92.32\n",
      "Average mean dist error: 9.03\n",
      "Average mean angle error: 14.71\n",
      "Average median dist error: 0.23\n",
      "Average median angle error: 2.46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
