{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SequencePointcloudRegistrationPipeline\n",
    "\n",
    "A module that implements an algorithm for optimizing the position and orientation of a vehicle in space based on a sequence of multimodal data using neural network methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1376/1736869189.py:15: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from copy import copy\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import faiss\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from hydra.utils import instantiate\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "from scipy.spatial.transform import Rotation\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "try:\n",
    "    from geotransformer.utils.registration import compute_registration_error\n",
    "    from geotransformer.utils.pointcloud import get_transform_from_rotation_translation\n",
    "except ImportError:\n",
    "    print(\"WARNING: geotransformer not installed, registration error will not be computed\")\n",
    "\n",
    "from opr.datasets import NCLTDataset\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline\n",
    "from opr.pipelines.registration.pointcloud import SequencePointcloudRegistrationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return dist_error, angle_error\n",
    "\n",
    "def compute_translation_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    gt_trans = gt_pose[:3, 3]\n",
    "    pred_trans = pred_pose[:3, 3]\n",
    "    error = np.linalg.norm(gt_trans - pred_trans)\n",
    "    return error\n",
    "\n",
    "def compute_rotation_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    gt_rot = Rotation.from_matrix(gt_pose[:3, :3])\n",
    "    pred_rot = Rotation.from_matrix(pred_pose[:3, :3])\n",
    "    error = Rotation.inv(gt_rot) * pred_rot\n",
    "    error = error.as_euler('xyz', degrees=True)\n",
    "    error = np.linalg.norm(error)\n",
    "    return error\n",
    "\n",
    "def compute_absolute_pose_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    rotation_error = compute_rotation_error(gt_pose, pred_pose)\n",
    "    translation_error = compute_translation_error(gt_pose, pred_pose)\n",
    "    return rotation_error, translation_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/docker_opr/Datasets/NCLT_preprocessed\"\n",
    "\n",
    "SENSOR_SUITE = [\"image_Cam5\", \"image_Cam2\", \"pointcloud_lidar\"]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "REGISTRATION_MODEL_CONFIG_PATH = \"../../configs/model/registration/geotransformer_kitti.yaml\"\n",
    "REGISTRATION_WEIGHTS_PATH = \"../../weights/registration/geotransformer_kitti.pth\"\n",
    "\n",
    "MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_lidar_late-fusion_nclt.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 tracks\n",
      "['2012-01-08', '2012-01-22', '2012-02-12', '2012-02-18', '2012-03-31', '2012-05-26', '2012-08-04', '2012-10-28', '2012-11-04', '2012-12-01']\n",
      "WARNING: track list limited\n",
      "['2012-01-08', '2012-01-22']\n"
     ]
    }
   ],
   "source": [
    "TRACK_LIST = sorted([str(subdir.name) for subdir in Path(DATASET_ROOT).iterdir() if subdir.is_dir()])\n",
    "print(f\"Found {len(TRACK_LIST)} tracks\")\n",
    "print(TRACK_LIST)\n",
    "\n",
    "print(\"WARNING: track list limited\")\n",
    "TRACK_LIST = TRACK_LIST[:2]\n",
    "print(TRACK_LIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = OmegaConf.load(MODEL_CONFIG_PATH)\n",
    "model = instantiate(model_config)\n",
    "model.load_state_dict(torch.load(WEIGHTS_PATH))\n",
    "model = model.to(DEVICE)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate descriptors for databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NCLTDataset(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    data_to_load=SENSOR_SUITE,\n",
    "    pointcloud_quantization_size=0.5,\n",
    "    max_point_distance=None,\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=dataset.collate_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 86/86 [00:14<00:00,  5.76it/s]\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        final_descriptor = model(batch)[\"final_descriptor\"]\n",
    "        descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "\n",
    "descriptors = np.concatenate(descriptors, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving database indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-01-08/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-01-22/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-02-12/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-02-18/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-03-31/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-05-26/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-08-04/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-10-28/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-11-04/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/NCLT_preprocessed/2012-12-01/index.faiss\n"
     ]
    }
   ],
   "source": [
    "dataset_df = dataset.dataset_df\n",
    "\n",
    "for track, indices in dataset_df.groupby(\"track\").groups.items():\n",
    "    track_descriptors = descriptors[indices]\n",
    "    track_index = faiss.IndexFlatL2(track_descriptors.shape[1])\n",
    "    track_index.add(track_descriptors)\n",
    "    faiss.write_index(track_index, f\"{DATASET_ROOT}/{track}/index.faiss\")\n",
    "    print(f\"Saved index {DATASET_ROOT}/{track}/index.faiss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init GeoTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotransformer = instantiate(OmegaConf.load(REGISTRATION_MODEL_CONFIG_PATH))\n",
    "\n",
    "registration_pipe = SequencePointcloudRegistrationPipeline(\n",
    "    model=geotransformer,\n",
    "    model_weights_path=REGISTRATION_WEIGHTS_PATH,\n",
    "    device=\"cuda\",  # the GeoTransformer currently only supports CUDA\n",
    "    voxel_downsample_size=0.5,  # recommended for geotransformer_kitti configuration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 274/274 [00:14<00:00, 19.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 274/274 [05:14<00:00,  1.15s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 330/330 [00:18<00:00, 18.31it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 330/330 [05:56<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "PR_THRESHOLD = 25.0\n",
    "\n",
    "test_csv = pd.read_csv(Path(DATASET_ROOT) / \"test.csv\", index_col=0)\n",
    "\n",
    "all_recalls = []\n",
    "all_mean_dist_errors = []\n",
    "all_mean_angle_errors = []\n",
    "all_median_dist_errors = []\n",
    "all_median_angle_errors = []\n",
    "all_times = []\n",
    "\n",
    "for db_track in TRACK_LIST:\n",
    "    pipe = PlaceRecognitionPipeline(\n",
    "        database_dir=Path(DATASET_ROOT) / db_track,\n",
    "        model=model,\n",
    "        model_weights_path=WEIGHTS_PATH,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    for query_track in TRACK_LIST:\n",
    "        if db_track == query_track:\n",
    "            continue\n",
    "        query_dataset = copy(dataset)\n",
    "        query_dataset.dataset_df = query_dataset.dataset_df[query_dataset.dataset_df[\"track\"] == query_track]\n",
    "        db_dataset = copy(dataset)\n",
    "        db_dataset.dataset_df = db_dataset.dataset_df[db_dataset.dataset_df[\"track\"] == db_track]\n",
    "        query_df = pd.read_csv(Path(DATASET_ROOT) / query_track / \"track.csv\", index_col=0)\n",
    "\n",
    "        # filter out only test subset\n",
    "        query_df = query_df[query_df['image'].isin(query_dataset.dataset_df['image'])].reset_index(drop=True)\n",
    "        # and do not forget to change the database_df in the pipeline\n",
    "        pipe.database_df = pipe.database_df[pipe.database_df['image'].isin(test_csv['image'])].reset_index(drop=True)\n",
    "\n",
    "        pr_matches = []\n",
    "        dist_errors = []\n",
    "        angle_errors = []\n",
    "        times = []\n",
    "\n",
    "        true_pairs = []\n",
    "        false_pairs = []\n",
    "\n",
    "        # STAGE 1 - place recognition\n",
    "        db_matches = {}\n",
    "        for q_i in tqdm(range(1, len(query_dataset)), total=len(query_dataset)-1):\n",
    "            query = query_dataset[q_i]\n",
    "            query[\"pose\"] = query_df.iloc[q_i][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "            output = pipe.infer(query)\n",
    "            db_matches[q_i] = output[\"idx\"]\n",
    "        torch.cuda.empty_cache()\n",
    "        # STAGE 2 - registration\n",
    "        for q_i in tqdm(range(1, len(query_dataset)), total=len(query_dataset)-1):\n",
    "            query = query_dataset[q_i]\n",
    "            query_seq = [query_dataset[q_i-1][\"pointcloud_lidar_coords\"], query_dataset[q_i][\"pointcloud_lidar_coords\"]]\n",
    "            # query_seq = [query_dataset[q_i][\"pointcloud_lidar_coords\"]]\n",
    "            output_idx = db_matches[q_i]\n",
    "            db_match = db_dataset[output_idx]\n",
    "            torch.cuda.empty_cache()\n",
    "            db_match[\"pose\"] = pipe.database_df.iloc[output_idx][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "            db_pose = pose_to_matrix(db_match[\"pose\"])\n",
    "            db_pc = db_match[\"pointcloud_lidar_coords\"]\n",
    "            t = time()\n",
    "            estimated_transformation = registration_pipe.infer(query_seq, db_pc)\n",
    "            times.append(time() - t)\n",
    "            optimized_pose = db_pose @ estimated_transformation\n",
    "            torch.cuda.empty_cache()\n",
    "            query[\"pose\"] = query_df.iloc[q_i][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "            angle_error, dist_error = compute_absolute_pose_error(optimized_pose, pose_to_matrix(query[\"pose\"]))\n",
    "            pr_matches.append(dist_error < PR_THRESHOLD)\n",
    "            dist_errors.append(dist_error)\n",
    "            angle_errors.append(angle_error)\n",
    "\n",
    "        all_recalls.append(np.mean(pr_matches))\n",
    "        all_mean_dist_errors.append(np.mean(dist_errors))\n",
    "        all_mean_angle_errors.append(np.mean(angle_errors))\n",
    "        all_median_dist_errors.append(np.median(dist_errors))\n",
    "        all_median_angle_errors.append(np.median(angle_errors))\n",
    "        all_times.extend(times[1:]) # drop the first iteration cause it is always slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_str = f\"\"\"Average Recall@1: {np.mean(all_recalls)*100:.2f}\n",
    "Average mean dist error: {np.mean(all_mean_dist_errors):.2f}\n",
    "Average mean angle error: {np.mean(all_mean_angle_errors):.2f}\n",
    "Average median dist error: {np.mean(all_median_dist_errors):.2f}\n",
    "Average median angle error: {np.mean(all_median_angle_errors):.2f}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall@1: 92.05\n",
      "Average mean dist error: 11.34\n",
      "Average mean angle error: 155.24\n",
      "Average median dist error: 3.03\n",
      "Average median angle error: 152.84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
