{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to prepare a faiss index file for Place Recognition pipeline\n",
    "\n",
    "This tutorial shows how to prepare a faiss index file for the Place Recognition pipeline. The index file is a binary file that contains the descriptors of the places in the database. The index file is used by the `PlaceRecognitionPipeline` to perform the Place Recognition task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import faiss\n",
    "from hydra.utils import instantiate\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from opr.datasets.itlp import ITLPCampus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_TRACK_DIR = \"/home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor/00_2023-02-10\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "MODEL_CONFIG_PATH = \"../configs/model/place_recognition/minkloc3d.yaml\"\n",
    "WEIGHTS_PATH = \"../weights/place_recognition/minkloc3d_nclt.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Initialize dataset and dataloader\n",
    "\n",
    "For this example, we will use the ITLP-Campus outdoor dataset with only LiDAR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dataset = ITLPCampus(\n",
    "    dataset_root=DATABASE_TRACK_DIR,\n",
    "    sensors=[\"lidar\"],\n",
    "    mink_quantization_size=0.5,\n",
    "    load_semantics=False,\n",
    "    load_text_descriptions=False,\n",
    "    load_text_labels=False,\n",
    "    load_aruco_labels=False,\n",
    "    indoor=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "609"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['idx', 'pose', 'pointcloud_lidar_coords', 'pointcloud_lidar_feats'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dataloader = DataLoader(\n",
    "    db_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=db_dataset.collate_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['idxs', 'poses', 'pointclouds_lidar_coords', 'pointclouds_lidar_feats'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = next(iter(db_dataloader))\n",
    "sample_batch.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Initialize model\n",
    "\n",
    "We will use hydra's `instantiate` function to initialize the model. The model is a `MinkLoc3D` - a simple LiDAR-only architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-20 14:10:06.365\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mopr.models.place_recognition.pointmamba\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[33m\u001b[1mThe 'pointmamba' package is not installed. Please install it manually if neccessary.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_config = OmegaConf.load(MODEL_CONFIG_PATH)\n",
    "model = instantiate(model_config)\n",
    "model.load_state_dict(torch.load(WEIGHTS_PATH))\n",
    "model = model.to(DEVICE)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Calculate descriptors\n",
    "\n",
    "We will calculate the descriptors for each place in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.42it/s]\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(db_dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        final_descriptor = model(batch)[\"final_descriptor\"]\n",
    "        descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "\n",
    "descriptors = np.concatenate(descriptors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Build faiss index & write it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "609\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatL2(descriptors.shape[1])\n",
    "index.add(descriptors)\n",
    "print(index.is_trained)\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, DATABASE_TRACK_DIR + \"/index.faiss\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "As a result, we now have a Faiss index file that can be used by the `PlaceRecognitionPipeline` to perform the Place Recognition task.\n",
    "\n",
    "In this example, the file is saved in the same directory as the track data. However, in a general case, the index file can be saved anywhere. The minimum requirement to initialize the `PlaceRecognitionPipeline` is that the database directory should contain both the `index.faiss` file and the `track.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aruco_labels/\n",
      "back_cam/\n",
      "front_cam/\n",
      "lidar/\n",
      "masks/\n",
      "text_descriptions/\n",
      "text_labels/\n",
      "demo.mp4\n",
      "index.faiss\n",
      "meta_info.yml\n",
      "track.csv\n",
      "track_map.png\n"
     ]
    }
   ],
   "source": [
    "dirs = [d for d in os.listdir(DATABASE_TRACK_DIR) if os.path.isdir(os.path.join(DATABASE_TRACK_DIR, d))]\n",
    "files = [f for f in os.listdir(DATABASE_TRACK_DIR) if os.path.isfile(os.path.join(DATABASE_TRACK_DIR, f))]\n",
    "\n",
    "\n",
    "for item in sorted(dirs):\n",
    "    print(item + \"/\")\n",
    "for item in sorted(files):\n",
    "    print(item)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
