{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import cv2\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.spatial.transform import Rotation\n",
    "from geotransformer.utils.pointcloud import get_transform_from_rotation_translation\n",
    "\n",
    "from opr.datasets.itlp import ITLPCampus\n",
    "from opr.pipelines.localization import ArucoLocalizationPipeline\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline\n",
    "from opr.pipelines.registration import PointcloudRegistrationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the dataset:\n",
    "\n",
    "- Kaggle:\n",
    "  - [ITLP Campus Outdoor](https://www.kaggle.com/datasets/alexandermelekhin/itlp-campus-outdoor)\n",
    "- Hugging Face:\n",
    "  - [ITLP Campus Outdoor](https://huggingface.co/datasets/OPR-Project/ITLP-Campus-Outdoor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test track list:\n",
      "['05_2023-08-15-day', '06_2023-08-18-night', '07_2023-10-04-day', '08_2023-10-11-night']\n"
     ]
    }
   ],
   "source": [
    "DATASET_ROOT = \"/home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor\"\n",
    "SENSOR_SUITE = [\"front_cam\", \"back_cam\", \"lidar\"]\n",
    "TRACK_LIST = sorted([str(subdir.name) for subdir in Path(DATASET_ROOT).iterdir() if subdir.is_dir()])[5:]\n",
    "\n",
    "print(\"Test track list:\")\n",
    "print(TRACK_LIST)\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 18\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 18) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return angle_error, dist_error\n",
    "\n",
    "def inference():\n",
    "    for db_track in TRACK_LIST:\n",
    "        pr_pipe = PlaceRecognitionPipeline(\n",
    "            database_dir=Path(DATASET_ROOT) / db_track,\n",
    "            model=pr_model,\n",
    "            model_weights_path=PR_WEIGHTS_PATH,\n",
    "            device=DEVICE,\n",
    "        )\n",
    "        for query_track in TRACK_LIST:\n",
    "            if db_track == query_track:\n",
    "                continue\n",
    "\n",
    "            reg_pipe = PointcloudRegistrationPipeline(\n",
    "                model=reg_model,\n",
    "                model_weights_path=REGISTRATION_WEIGHTS_PATH,\n",
    "                device=DEVICE,\n",
    "                voxel_downsample_size=0.3,\n",
    "                num_points_downsample=8192,\n",
    "            )\n",
    "            loc_pipe = ArucoLocalizationPipeline(\n",
    "                place_recognition_pipeline=pr_pipe,\n",
    "                registration_pipeline=reg_pipe,\n",
    "                precomputed_reg_feats=True,\n",
    "                pointclouds_subdir=\"lidar\",\n",
    "                aruco_metadata=aruco_metadata,\n",
    "                camera_metadata=camera_metadata,\n",
    "                fastest=True,\n",
    "                use_first_marker=True\n",
    "            )\n",
    "\n",
    "            query_dataset = copy.deepcopy(test_query_dataset)\n",
    "            query_dataset.dataset_df = query_dataset.dataset_df[query_dataset.dataset_df[\"track\"] == query_track].reset_index(drop=True)\n",
    "            query_df = query_dataset.dataset_df\n",
    "            ###\n",
    "            # specific for aruco\n",
    "            query_dataset.image_transform = lambda x: x\n",
    "\n",
    "            db_dataset = copy.deepcopy(test_db_dataset)\n",
    "            db_dataset.dataset_df = db_dataset.dataset_df[db_dataset.dataset_df[\"track\"] == db_track].reset_index(drop=True)\n",
    "            db_df = db_dataset.dataset_df\n",
    "            ###\n",
    "            # specific for aruco\n",
    "            db_dataset.image_transform = lambda x: x\n",
    "            warmup_sample = db_dataset[0]\n",
    "\n",
    "            loc_pipe.pr_pipe.database_df = db_df\n",
    "            loc_pipe.database_df = db_df\n",
    "\n",
    "            reg_matches_aruco = []\n",
    "            reg_rotation_errors_aruco = []\n",
    "            reg_translation_errors_aruco = []\n",
    "            times_aruco = []\n",
    "\n",
    "            # fake launch to run first long call of torch model\n",
    "            _ = loc_pipe.loc_part(warmup_sample)\n",
    "\n",
    "            for q_i, query in tqdm(enumerate(query_dataset)):\n",
    "                query_pose = query_df.iloc[q_i][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "                start = time()\n",
    "                output = loc_pipe.infer(query)\n",
    "                torch.cuda.current_stream().synchronize()\n",
    "                step_time = time() - start\n",
    "                times_aruco.append(step_time)\n",
    "\n",
    "                estimated_pose = output[\"pose_by_aruco\"] if output[\"pose_by_aruco\"] is not None else output[\"pose_by_place_recognition\"]\n",
    "\n",
    "                reg_rotation_error_aruco, reg_translation_error_aruco = compute_error(estimated_pose, query_pose)\n",
    "                reg_correct_aruco = reg_translation_error_aruco < RECALL_THRESHOLD\n",
    "                reg_matches_aruco.append(reg_correct_aruco)\n",
    "                reg_rotation_errors_aruco.append(reg_rotation_error_aruco)\n",
    "                reg_translation_errors_aruco.append(reg_translation_error_aruco)\n",
    "\n",
    "            all_reg_recalls_aruco.append(np.nanmean(reg_matches_aruco))\n",
    "            all_mean_reg_rotation_errors_aruco.append(np.nanmean(reg_rotation_errors_aruco))\n",
    "            all_mean_reg_translation_errors_aruco.append(np.nanmean(reg_translation_errors_aruco))\n",
    "            all_median_reg_rotation_errors_aruco.append(np.nanmedian(reg_rotation_errors_aruco))\n",
    "            all_median_reg_translation_errors_aruco.append(np.nanmedian(reg_translation_errors_aruco))\n",
    "            all_times_aruco.extend(times_aruco)\n",
    "\n",
    "        results_str_aruco = f\"\"\"Average REG Recall@1:  {np.nanmean(all_reg_recalls_aruco)*100:.2f}\n",
    "        Average Mean RRE REG:  {np.nanmean(all_mean_reg_rotation_errors_aruco):.2f}\n",
    "        Average Mean RTE REG:  {np.nanmean(all_mean_reg_translation_errors_aruco):.2f}\n",
    "        Average Median RRE REG:  {np.nanmean(all_median_reg_rotation_errors_aruco):.2f}\n",
    "        Average Median RTE REG:  {np.nanmean(all_median_reg_translation_errors_aruco):.2f}\n",
    "        Mean inference time:     {np.nanmean(all_times_aruco)*1000:.2f} ms\n",
    "        \"\"\"\n",
    "    return results_str_aruco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_dataset = ITLPCampus(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    csv_file=\"aruco_test.csv\",\n",
    "    sensors=SENSOR_SUITE,\n",
    ")\n",
    "test_db_dataset = ITLPCampus(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    csv_file=\"test.csv\",\n",
    "    sensors=SENSOR_SUITE,\n",
    ")\n",
    "test_db_dataset.dataset_df = test_db_dataset.dataset_df[test_db_dataset.dataset_df[\"track\"].isin(TRACK_LIST)]\n",
    "test_db_dataset.dataset_df.reset_index(inplace=True)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    test_db_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=test_db_dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_metadata = {\n",
    "    \"front_cam_intrinsics\": [[683.6199340820312, 0.0, 615.1160278320312],\n",
    "                             [0.0, 683.6199340820312, 345.32354736328125],\n",
    "                             [0.0, 0.0, 1.0]],\n",
    "    \"front_cam_distortion\": [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    \"front_cam2baselink\": [-0.2388, 0.06, 0.75, -0.5, 0.49999999999755174, -0.5, 0.5000000000024483],\n",
    "    \"back_cam_intrinsics\": [[910.4178466796875, 0.0, 648.44140625],\n",
    "                            [0.0, 910.4166870117188, 354.0118408203125],\n",
    "                            [0.0, 0.0, 1.0]],\n",
    "    \"back_cam_distortion\": [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    \"back_cam2baselink\": [-0.3700594606670597, -0.006647301538708517, 0.7427924789987381, -0.4981412857230513, -0.4907829006275322, 0.5090864815669471, 0.5018149813673275]\n",
    "}\n",
    "\n",
    "aruco_metadata = {\n",
    "    \"aruco_type\": cv2.aruco.DICT_4X4_250,\n",
    "    \"aruco_size\": 0.2,\n",
    "    \"aruco_gt_pose_by_id\": {\n",
    "        0: [-23.76325316, 16.94296093, 1.51796168, 0.25454437, 0.65070725, 0.6526984, 0.29286864],\n",
    "        2: [-8.81475372, -12.47510287, 1.75787052, 0.61022095, -0.21494468, -0.21004688, 0.73301397],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRATION_MODEL_CONFIG_PATH = \"../../configs/model/registration/hregnet_light_feats.yaml\"\n",
    "REGISTRATION_WEIGHTS_PATH = \"../../weights/registration/hregnet_light_feats_nuscenes.pth\"\n",
    "reg_model_config = OmegaConf.load(REGISTRATION_MODEL_CONFIG_PATH)\n",
    "reg_model = instantiate(reg_model_config)\n",
    "reg_model.load_state_dict(torch.load(REGISTRATION_WEIGHTS_PATH))\n",
    "reg_model = reg_model.to(DEVICE)\n",
    "reg_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCLT\n",
    "\n",
    "all_reg_recalls_aruco = []\n",
    "all_mean_reg_rotation_errors_aruco = []\n",
    "all_mean_reg_translation_errors_aruco = []\n",
    "all_median_reg_rotation_errors_aruco = []\n",
    "all_median_reg_translation_errors_aruco = []\n",
    "all_times_aruco = []\n",
    "RECALL_THRESHOLD = 25.0\n",
    "\n",
    "PR_MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "PR_WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_lidar_late-fusion_nclt.pth\"\n",
    "pr_model_config = OmegaConf.load(PR_MODEL_CONFIG_PATH)\n",
    "pr_model = instantiate(pr_model_config)\n",
    "pr_model.load_state_dict(torch.load(PR_WEIGHTS_PATH))\n",
    "pr_model = pr_model.to(DEVICE)\n",
    "pr_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:11<00:00, 13.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/05_2023-08-15-day/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/06_2023-08-18-night/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/07_2023-10-04-day/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/08_2023-10-11-night/index.faiss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        final_descriptor = pr_model(batch)[\"final_descriptor\"]\n",
    "        descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "descriptors = np.concatenate(descriptors, axis=0)\n",
    "\n",
    "dataset_df = test_db_dataset.dataset_df\n",
    "for track, indices in dataset_df.groupby(\"track\").groups.items():\n",
    "    track_descriptors = descriptors[indices]\n",
    "    track_index = faiss.IndexFlatL2(track_descriptors.shape[1])\n",
    "    track_index.add(track_descriptors)\n",
    "    faiss.write_index(track_index, f\"{DATASET_ROOT}/{track}/index.faiss\")\n",
    "    print(f\"Saved index {DATASET_ROOT}/{track}/index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_front_cam\n",
      "Utilize Aruco with id [2] on image_front_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  4.95it/s]\n",
      "0it [00:00, ?it/s]\n",
      "3it [00:00,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "3it [00:00,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_front_cam\n",
      "Utilize Aruco with id [2] on image_front_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_front_cam\n",
      "Utilize Aruco with id [2] on image_front_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average REG Recall@1:  100.00\n",
      "        Average Mean RRE REG:  16.32\n",
      "        Average Mean RTE REG:  4.81\n",
      "        Average Median RRE REG:  15.89\n",
      "        Average Median RTE REG:  4.73\n",
      "        Mean inference time:     95.60 ms\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(inference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIPT finetune\n",
    "\n",
    "all_reg_recalls_aruco = []\n",
    "all_mean_reg_rotation_errors_aruco = []\n",
    "all_mean_reg_translation_errors_aruco = []\n",
    "all_median_reg_rotation_errors_aruco = []\n",
    "all_median_reg_translation_errors_aruco = []\n",
    "all_times_aruco = []\n",
    "RECALL_THRESHOLD = 25.0\n",
    "\n",
    "PR_MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "PR_WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_lidar_late-fusion_itlp-finetune.pth\"\n",
    "pr_model_config = OmegaConf.load(PR_MODEL_CONFIG_PATH)\n",
    "pr_model = instantiate(pr_model_config)\n",
    "pr_model.load_state_dict(torch.load(PR_WEIGHTS_PATH))\n",
    "pr_model = pr_model.to(DEVICE)\n",
    "pr_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:08<00:00, 18.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/05_2023-08-15-day/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/06_2023-08-18-night/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/07_2023-10-04-day/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/08_2023-10-11-night/index.faiss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        final_descriptor = pr_model(batch)[\"final_descriptor\"]\n",
    "        descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "descriptors = np.concatenate(descriptors, axis=0)\n",
    "\n",
    "dataset_df = test_db_dataset.dataset_df\n",
    "for track, indices in dataset_df.groupby(\"track\").groups.items():\n",
    "    track_descriptors = descriptors[indices]\n",
    "    track_index = faiss.IndexFlatL2(track_descriptors.shape[1])\n",
    "    track_index.add(track_descriptors)\n",
    "    faiss.write_index(track_index, f\"{DATASET_ROOT}/{track}/index.faiss\")\n",
    "    print(f\"Saved index {DATASET_ROOT}/{track}/index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_front_cam\n",
      "Utilize Aruco with id [2] on image_front_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  6.42it/s]\n",
      "0it [00:00, ?it/s]\n",
      "3it [00:00,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "3it [00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_front_cam\n",
      "Utilize Aruco with id [2] on image_front_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3it [00:00,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2it [00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_back_cam\n",
      "Utilize Aruco with id [2] on image_back_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect Aruco with id [2] on image_front_cam\n",
      "Utilize Aruco with id [2] on image_front_cam for pose estimation due min distanse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average REG Recall@1:  100.00\n",
      "        Average Mean RRE REG:  14.99\n",
      "        Average Mean RTE REG:  3.77\n",
      "        Average Median RRE REG:  14.74\n",
      "        Average Median RTE REG:  3.79\n",
      "        Mean inference time:     90.14 ms\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(inference())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
