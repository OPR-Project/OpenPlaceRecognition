{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LateFusionModel with semantics - ITLP dataset test\n",
    "\n",
    "A module that implements a neural network algorithm for searching a database of places already visited by a vehicle for the most similar records using sequences of data from lidars and cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-01 11:57:41.981\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mopr.models.place_recognition.pointmamba\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[33m\u001b[1mThe 'pointmamba' package is not installed. Please install it manually if neccessary.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import open3d.core as o3c\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "from scipy.spatial.transform import Rotation\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from opr.datasets.itlp import ITLPCampus\n",
    "from opr.models.place_recognition.base import LateFusionModel\n",
    "from opr.testing import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DISPLAY\"] = \":1\"\n",
    "\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "\n",
    "# def compute_error(estimated_pose, gt_pose):\n",
    "#     \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "#     estimated_pose = pose_to_matrix(estimated_pose)\n",
    "#     gt_pose = pose_to_matrix(gt_pose)\n",
    "#     return compute_registration_error(estimated_pose, gt_pose)\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return angle_error, dist_error\n",
    "\n",
    "\n",
    "def draw_pc(pc: Tensor, color: str = \"blue\"):\n",
    "    pc_o3d = o3c.Tensor.from_dlpack(torch.utils.dlpack.to_dlpack(pc))\n",
    "    pcd = o3d.t.geometry.PointCloud(pc_o3d)\n",
    "    if color == \"blue\":\n",
    "        c = [0.0, 0.0, 1.0]\n",
    "    elif color == \"red\":\n",
    "        c = [1.0, 0.0, 0.0]\n",
    "    else:\n",
    "        c = [0.0, 1.0, 0.0]\n",
    "    pcd = pcd.paint_uniform_color(c)\n",
    "    o3d.visualization.draw_geometries(\n",
    "        [pcd.to_legacy()],\n",
    "    )\n",
    "\n",
    "\n",
    "def invert_rigid_transformation_matrix(T: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Inverts a 4x4 rigid body transformation matrix.\n",
    "\n",
    "    Args:\n",
    "        T (np.ndarray): A 4x4 rigid body transformation matrix.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The inverted 4x4 rigid body transformation matrix.\n",
    "    \"\"\"\n",
    "    assert T.shape == (4, 4), \"Input matrix must be 4x4.\"\n",
    "\n",
    "    R = T[:3, :3]\n",
    "    t = T[:3, 3]\n",
    "\n",
    "    R_inv = R.T\n",
    "    t_inv = -R.T @ t\n",
    "\n",
    "    T_inv = np.eye(4)\n",
    "    T_inv[:3, :3] = R_inv\n",
    "    T_inv[:3, 3] = t_inv\n",
    "\n",
    "    return T_inv\n",
    "\n",
    "\n",
    "def draw_pc_pair(\n",
    "    pc_blue: Tensor, pc_blue_pose: np.ndarray | Tensor, pc_red: Tensor, pc_red_pose: np.ndarray | Tensor\n",
    "):\n",
    "    pc_blue_o3d = o3c.Tensor.from_dlpack(torch.utils.dlpack.to_dlpack(copy.deepcopy(pc_blue)))\n",
    "    pc_red_o3d = o3c.Tensor.from_dlpack(torch.utils.dlpack.to_dlpack(copy.deepcopy(pc_red)))\n",
    "\n",
    "    blue_pcd = o3d.t.geometry.PointCloud(pc_blue_o3d)\n",
    "    blue_pcd_tmp = copy.deepcopy(blue_pcd)\n",
    "\n",
    "    red_pcd = o3d.t.geometry.PointCloud(pc_red_o3d)\n",
    "    red_pcd_tmp = copy.deepcopy(red_pcd)\n",
    "\n",
    "    blue_pcd_tmp.voxel_down_sample(voxel_size=0.3)\n",
    "    # blue_pcd_tmp.transform(pose_to_matrix(pc_blue_pose))\n",
    "    blue_pcd_tmp = blue_pcd_tmp.paint_uniform_color([0.0, 0.0, 1.0])\n",
    "\n",
    "    red_pcd_tmp.voxel_down_sample(voxel_size=0.3)\n",
    "    red_pcd_tmp.transform(pose_to_matrix(pc_red_pose))\n",
    "    red_pcd_tmp.transform(invert_rigid_transformation_matrix(pose_to_matrix(pc_blue_pose)))\n",
    "    red_pcd_tmp = red_pcd_tmp.paint_uniform_color([1.0, 0.0, 0.0])\n",
    "    o3d.visualization.draw_geometries(\n",
    "        [blue_pcd_tmp.to_legacy(), red_pcd_tmp.to_legacy()],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can **download the dataset**:\n",
    "\n",
    "- Kaggle:\n",
    "  - [ITLP Campus Outdoor](https://www.kaggle.com/datasets/alexandermelekhin/itlp-campus-outdoor)\n",
    "- Hugging Face:\n",
    "  - [ITLP Campus Outdoor](https://huggingface.co/datasets/OPR-Project/ITLP-Campus-Outdoor)\n",
    "\n",
    "To **download the model weights**, run the following command:\n",
    "\n",
    "```bash\n",
    "# place recognition weights\n",
    "wget -O ../../weights/place_recognition/multi-image_multi-semantic_lidar_late-fusion_nclt.pth https://huggingface.co/OPR-Project/PlaceRecognition-NCLT/resolve/main/multi-image_multi-semantic_lidar_late-fusion_nclt.pth\n",
    "wget -O ../../weights/place_recognition/multi-image_multi-semantic_lidar_late-fusion_itlp-finetune.pth https://huggingface.co/OPR-Project/PlaceRecognition-NCLT/resolve/main/multi-image_multi-semantic_lidar_late-fusion_itlp-finetune.pth\n",
    "\n",
    "# registration weights\n",
    "wget -O ../../weights/registration/hregnet_light_feats_nuscenes.pth https://huggingface.co/OPR-Project/Registration-nuScenes/resolve/main/hregnet_light_feats_nuscenes.pth\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place recognition weights\n",
    "!wget -O ../../weights/place_recognition/multi-image_multi-semantic_lidar_late-fusion_nclt.pth https://huggingface.co/OPR-Project/PlaceRecognition-NCLT/resolve/main/multi-image_multi-semantic_lidar_late-fusion_nclt.pth\n",
    "!wget -O ../../weights/place_recognition/multi-image_multi-semantic_lidar_late-fusion_itlp-finetune.pth https://huggingface.co/OPR-Project/PlaceRecognition-NCLT/resolve/main/multi-image_multi-semantic_lidar_late-fusion_itlp-finetune.pth\n",
    "\n",
    "# registration weights\n",
    "!wget -O ../../weights/registration/hregnet_light_feats_nuscenes.pth https://huggingface.co/OPR-Project/Registration-nuScenes/resolve/main/hregnet_light_feats_nuscenes.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test track list:\n",
      "['05_2023-08-15-day', '06_2023-08-18-night', '07_2023-10-04-day', '08_2023-10-11-night']\n"
     ]
    }
   ],
   "source": [
    "DATASET_ROOT = \"/home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor\"\n",
    "\n",
    "TRACK_LIST = sorted(\n",
    "    [str(subdir.name) for subdir in Path(DATASET_ROOT).iterdir() if subdir.is_dir() and not subdir.name.startswith(\".\")]\n",
    ")\n",
    "TRACK_LIST = TRACK_LIST[5:]\n",
    "\n",
    "print(\"Test track list:\")\n",
    "print(TRACK_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_SUITE = [\"front_cam\", \"back_cam\", \"lidar\"]\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "PR_MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_multi-semantic_lidar_late-fusion.yaml\"\n",
    "PR_WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_multi-semantic_lidar_late-fusion_nclt.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_model_config = OmegaConf.load(PR_MODEL_CONFIG_PATH)\n",
    "pr_model = instantiate(pr_model_config)\n",
    "pr_model.load_state_dict(torch.load(PR_WEIGHTS_PATH))\n",
    "pr_model = pr_model.to(DEVICE)\n",
    "pr_model.eval();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ITLPCampus(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    csv_file=\"test.csv\",\n",
    "    sensors=SENSOR_SUITE,\n",
    "    load_semantics=True,\n",
    ")\n",
    "dataset.dataset_df = dataset.dataset_df[dataset.dataset_df[\"track\"].isin(TRACK_LIST)]\n",
    "dataset.dataset_df.reset_index(inplace=True)\n",
    "\n",
    "no_masks = []\n",
    "no_masks_filenames = []\n",
    "\n",
    "for index, row in dataset.dataset_df.iterrows():\n",
    "    mask_path = f\"{DATASET_ROOT}/{row['track']}/masks/back_cam/{row['back_cam_ts']}.png\"\n",
    "    filename = f\"{row['back_cam_ts']}.png\"\n",
    "    if not Path(mask_path).exists():\n",
    "        no_masks.append(index)\n",
    "        no_masks_filenames.append(filename)\n",
    "\n",
    "dataset.dataset_df.drop(no_masks, inplace=True)\n",
    "dataset.dataset_df.reset_index(inplace=True)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=dataset.collate_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    }
   ],
   "source": [
    "ar_at_n, ar_at_1per, mean_top1_distance = test(model=pr_model, dataloader=dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean top-1 Euclidean distance: 1.3713\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean top-1 Euclidean distance: {mean_top1_distance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_SUITE = [\"front_cam\", \"back_cam\", \"lidar\"]\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "PR_MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_multi-semantic_lidar_late-fusion.yaml\"\n",
    "PR_WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_multi-semantic_lidar_late-fusion_itlp-finetune.pth\"\n",
    "\n",
    "REGISTRATION_MODEL_CONFIG_PATH = \"../../configs/model/registration/hregnet_light_feats.yaml\"\n",
    "REGISTRATION_WEIGHTS_PATH = \"../../weights/registration/hregnet_light_feats_nuscenes.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_model_config = OmegaConf.load(PR_MODEL_CONFIG_PATH)\n",
    "pr_model = instantiate(pr_model_config)\n",
    "pr_model.load_state_dict(torch.load(PR_WEIGHTS_PATH))\n",
    "pr_model = pr_model.to(DEVICE)\n",
    "pr_model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ITLPCampus(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    csv_file=\"test.csv\",\n",
    "    sensors=SENSOR_SUITE,\n",
    "    load_semantics=True,\n",
    ")\n",
    "dataset.dataset_df = dataset.dataset_df[dataset.dataset_df[\"track\"].isin(TRACK_LIST)]\n",
    "dataset.dataset_df.reset_index(inplace=True)\n",
    "\n",
    "no_masks = []\n",
    "no_masks_filenames = []\n",
    "\n",
    "for index, row in dataset.dataset_df.iterrows():\n",
    "    mask_path = f\"{DATASET_ROOT}/{row['track']}/masks/back_cam/{row['back_cam_ts']}.png\"\n",
    "    filename = f\"{row['back_cam_ts']}.png\"\n",
    "    if not Path(mask_path).exists():\n",
    "        no_masks.append(index)\n",
    "        no_masks_filenames.append(filename)\n",
    "\n",
    "dataset.dataset_df.drop(no_masks, inplace=True)\n",
    "dataset.dataset_df.reset_index(inplace=True)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=dataset.collate_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    }
   ],
   "source": [
    "ar_at_n, ar_at_1per, mean_top1_distance = test(model=pr_model, dataloader=dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean top-1 Euclidean distance: 1.2725\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean top-1 Euclidean distance: {mean_top1_distance:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
