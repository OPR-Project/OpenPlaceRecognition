{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import cv2\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.spatial.transform import Rotation\n",
    "from geotransformer.utils.pointcloud import get_transform_from_rotation_translation\n",
    "\n",
    "from opr.datasets.itlp import ITLPCampus\n",
    "from opr.pipelines.localization import LocalizationPipeline\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline\n",
    "from opr.pipelines.registration import PointcloudRegistrationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test track list:\n",
      "['05_2023-08-15-day', '06_2023-08-18-night', '07_2023-10-04-day', '08_2023-10-11-night']\n"
     ]
    }
   ],
   "source": [
    "DATASET_ROOT = \"/home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2\"\n",
    "SENSOR_SUITE = [\"front_cam\", \"back_cam\", \"lidar\"]\n",
    "TRACK_LIST = sorted([str(subdir.name) for subdir in Path(DATASET_ROOT).iterdir() if subdir.is_dir()])[5:]\n",
    "\n",
    "print(\"Test track list:\")\n",
    "print(TRACK_LIST)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 18\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 18) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return angle_error, dist_error\n",
    "\n",
    "def inference():\n",
    "    for db_track in TRACK_LIST:\n",
    "        pr_pipe = PlaceRecognitionPipeline(\n",
    "            database_dir=Path(DATASET_ROOT) / db_track,\n",
    "            model=pr_model,\n",
    "            model_weights_path=PR_WEIGHTS_PATH,\n",
    "            device=DEVICE,\n",
    "        )\n",
    "        for query_track in TRACK_LIST:\n",
    "            if db_track == query_track:\n",
    "                continue\n",
    "\n",
    "            reg_pipe = PointcloudRegistrationPipeline(\n",
    "                model=reg_model,\n",
    "                model_weights_path=REGISTRATION_WEIGHTS_PATH,\n",
    "                device=DEVICE,\n",
    "                voxel_downsample_size=0.3,\n",
    "                num_points_downsample=8192,\n",
    "            )\n",
    "            loc_pipe = LocalizationPipeline(\n",
    "                place_recognition_pipeline=pr_pipe,\n",
    "                registration_pipeline=reg_pipe,\n",
    "                precomputed_reg_feats=True,\n",
    "                pointclouds_subdir=\"lidar\"\n",
    "            )\n",
    "\n",
    "            query_dataset = copy.deepcopy(dataset)\n",
    "            query_dataset.dataset_df = query_dataset.dataset_df[query_dataset.dataset_df[\"track\"] == query_track].reset_index(drop=True)\n",
    "            query_df = query_dataset.dataset_df\n",
    "\n",
    "            db_dataset = copy.deepcopy(dataset)\n",
    "            db_dataset.dataset_df = db_dataset.dataset_df[db_dataset.dataset_df[\"track\"] == db_track].reset_index(drop=True)\n",
    "            db_df = db_dataset.dataset_df\n",
    "\n",
    "            loc_pipe.pr_pipe.database_df = db_df\n",
    "            loc_pipe.database_df = db_df\n",
    "\n",
    "            reg_matches = []\n",
    "            reg_rotation_errors = []\n",
    "            reg_translation_errors = []\n",
    "            times = []\n",
    "\n",
    "            for q_i, query in tqdm(enumerate(query_dataset)):\n",
    "                query_pose = query_df.iloc[q_i][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "                start = time()\n",
    "                estimated_pose = loc_pipe.infer(query)[\"estimated_pose\"]\n",
    "                torch.cuda.current_stream().synchronize()\n",
    "                step_time = time() - start\n",
    "                times.append(step_time)\n",
    "\n",
    "                reg_rotation_error, reg_translation_error = compute_error(estimated_pose, query_pose)\n",
    "                reg_correct = reg_translation_error < RECALL_THRESHOLD\n",
    "                reg_matches.append(reg_correct)\n",
    "                reg_rotation_errors.append(reg_rotation_error)\n",
    "                reg_translation_errors.append(reg_translation_error)\n",
    "\n",
    "            all_reg_recalls.append(np.nanmean(reg_matches))\n",
    "            all_mean_reg_rotation_errors.append(np.nanmean(reg_rotation_errors))\n",
    "            all_mean_reg_translation_errors.append(np.nanmean(reg_translation_errors))\n",
    "            all_median_reg_rotation_errors.append(np.nanmedian(reg_rotation_errors))\n",
    "            all_median_reg_translation_errors.append(np.nanmedian(reg_translation_errors))\n",
    "            all_times.extend(times[1:])\n",
    "\n",
    "        results_str = f\"\"\"Average REG Recall@1:  {np.nanmean(all_reg_recalls)*100:.2f}\n",
    "        Average Mean RRE REG:  {np.nanmean(all_mean_reg_rotation_errors):.2f}\n",
    "        Average Mean RTE REG:  {np.nanmean(all_mean_reg_translation_errors):.2f}\n",
    "        Average Median RRE REG:  {np.nanmean(all_median_reg_rotation_errors):.2f}\n",
    "        Average Median RTE REG:  {np.nanmean(all_median_reg_translation_errors):.2f}\n",
    "        Mean inference time:     {np.nanmean(all_times)*1000:.2f} ms\n",
    "        \"\"\"\n",
    "    return results_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from opr.datasets.augmentations import DefaultImageTransform\n",
    "\n",
    "class ToTensorTransform:\n",
    "    def __init__(self):\n",
    "        transform_list = [ToTensorV2()]\n",
    "        self.transform = A.Compose(transform_list)\n",
    "\n",
    "    def __call__(self, img: np.ndarray):\n",
    "        \"\"\"Applies transformations to the given image.\"\"\"\n",
    "        return self.transform(image=img)[\"image\"]\n",
    "\n",
    "dataset = ITLPCampus(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    csv_file=\"test.csv\",\n",
    "    sensors=SENSOR_SUITE,\n",
    "    load_semantics=True,\n",
    "    exclude_dynamic_classes=True,\n",
    "    image_transform=ToTensorTransform(),\n",
    "    semantic_transform=ToTensorTransform(),\n",
    "    late_image_transform=DefaultImageTransform(resize=(320, 192), train=False)\n",
    ")\n",
    "dataset.dataset_df = dataset.dataset_df[dataset.dataset_df[\"track\"].isin(TRACK_LIST)]\n",
    "dataset.dataset_df.reset_index(inplace=True)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRATION_MODEL_CONFIG_PATH = \"../../configs/model/registration/hregnet_light_feats.yaml\"\n",
    "REGISTRATION_WEIGHTS_PATH = \"../../weights/registration/hregnet_light_feats_nuscenes.pth\"\n",
    "reg_model_config = OmegaConf.load(REGISTRATION_MODEL_CONFIG_PATH)\n",
    "reg_model = instantiate(reg_model_config)\n",
    "reg_model.load_state_dict(torch.load(REGISTRATION_WEIGHTS_PATH))\n",
    "reg_model = reg_model.to(DEVICE)\n",
    "reg_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCLT\n",
    "\n",
    "all_reg_recalls = []\n",
    "all_mean_reg_rotation_errors = []\n",
    "all_mean_reg_translation_errors = []\n",
    "all_median_reg_rotation_errors = []\n",
    "all_median_reg_translation_errors = []\n",
    "all_times = []\n",
    "RECALL_THRESHOLD = 25.0\n",
    "\n",
    "PR_MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "PR_WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_lidar_late-fusion_nclt.pth\"\n",
    "pr_model_config = OmegaConf.load(PR_MODEL_CONFIG_PATH)\n",
    "pr_model = instantiate(pr_model_config)\n",
    "pr_model.load_state_dict(torch.load(PR_WEIGHTS_PATH))\n",
    "pr_model = pr_model.to(DEVICE)\n",
    "pr_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [01:00<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/05_2023-08-15-day/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/06_2023-08-18-night/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/07_2023-10-04-day/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/08_2023-10-11-night/index.faiss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        final_descriptor = pr_model(batch)[\"final_descriptor\"]\n",
    "        descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "descriptors = np.concatenate(descriptors, axis=0)\n",
    "\n",
    "dataset_df = dataset.dataset_df\n",
    "for track, indices in dataset_df.groupby(\"track\").groups.items():\n",
    "    track_descriptors = descriptors[indices]\n",
    "    track_index = faiss.IndexFlatL2(track_descriptors.shape[1])\n",
    "    track_index.add(track_descriptors)\n",
    "    faiss.write_index(track_index, f\"{DATASET_ROOT}/{track}/index.faiss\")\n",
    "    print(f\"Saved index {DATASET_ROOT}/{track}/index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [00:59,  2.62it/s]\n",
      "152it [00:49,  3.06it/s]\n",
      "150it [00:46,  3.21it/s]\n",
      "152it [00:49,  3.09it/s]\n",
      "152it [00:49,  3.04it/s]\n",
      "150it [00:48,  3.12it/s]\n",
      "152it [00:48,  3.10it/s]\n",
      "156it [00:48,  3.19it/s]\n",
      "150it [00:47,  3.16it/s]\n",
      "152it [00:48,  3.11it/s]\n",
      "156it [00:49,  3.17it/s]\n",
      "152it [00:48,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average REG Recall@1:  96.61\n",
      "        Average Mean RRE REG:  10.64\n",
      "        Average Mean RTE REG:  5.90\n",
      "        Average Median RRE REG:  5.31\n",
      "        Average Median RTE REG:  2.62\n",
      "        Mean inference time:     119.56 ms\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(inference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIPT finetune\n",
    "\n",
    "all_reg_recalls = []\n",
    "all_mean_reg_rotation_errors = []\n",
    "all_mean_reg_translation_errors = []\n",
    "all_median_reg_rotation_errors = []\n",
    "all_median_reg_translation_errors = []\n",
    "all_times = []\n",
    "RECALL_THRESHOLD = 25.0\n",
    "\n",
    "PR_MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "PR_WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_lidar_late-fusion_itlp-finetune.pth\"\n",
    "pr_model_config = OmegaConf.load(PR_MODEL_CONFIG_PATH)\n",
    "pr_model = instantiate(pr_model_config)\n",
    "pr_model.load_state_dict(torch.load(PR_WEIGHTS_PATH))\n",
    "pr_model = pr_model.to(DEVICE)\n",
    "pr_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [01:05<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/05_2023-08-15-day/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/06_2023-08-18-night/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/07_2023-10-04-day/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/08_2023-10-11-night/index.faiss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        final_descriptor = pr_model(batch)[\"final_descriptor\"]\n",
    "        descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "descriptors = np.concatenate(descriptors, axis=0)\n",
    "\n",
    "dataset_df = dataset.dataset_df\n",
    "for track, indices in dataset_df.groupby(\"track\").groups.items():\n",
    "    track_descriptors = descriptors[indices]\n",
    "    track_index = faiss.IndexFlatL2(track_descriptors.shape[1])\n",
    "    track_index.add(track_descriptors)\n",
    "    faiss.write_index(track_index, f\"{DATASET_ROOT}/{track}/index.faiss\")\n",
    "    print(f\"Saved index {DATASET_ROOT}/{track}/index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [00:49,  3.15it/s]\n",
      "152it [00:49,  3.05it/s]\n",
      "150it [00:47,  3.15it/s]\n",
      "152it [00:50,  3.03it/s]\n",
      "152it [00:48,  3.10it/s]\n",
      "150it [00:48,  3.11it/s]\n",
      "152it [00:48,  3.13it/s]\n",
      "156it [00:48,  3.22it/s]\n",
      "150it [00:47,  3.16it/s]\n",
      "152it [00:48,  3.15it/s]\n",
      "156it [00:48,  3.19it/s]\n",
      "152it [00:49,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average REG Recall@1:  99.56\n",
      "        Average Mean RRE REG:  9.12\n",
      "        Average Mean RTE REG:  3.50\n",
      "        Average Median RRE REG:  4.86\n",
      "        Average Median RTE REG:  2.55\n",
      "        Mean inference time:     119.55 ms\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(inference())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
