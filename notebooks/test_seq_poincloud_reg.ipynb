{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SequencePointcloudRegistrationPipeline\n",
    "\n",
    "A module that implements an algorithm for optimizing the position and orientation of a vehicle in space based on a sequence of multimodal data using neural network methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "import faiss\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from hydra.utils import instantiate\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "from scipy.spatial.transform import Rotation\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "try:\n",
    "    from geotransformer.utils.registration import compute_registration_error\n",
    "    from geotransformer.utils.pointcloud import get_transform_from_rotation_translation\n",
    "except ImportError:\n",
    "    print(\"WARNIGN: geotransformer not installed, registration error will not be computed\")\n",
    "\n",
    "from opr.datasets.itlp import ITLPCampus\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline\n",
    "from opr.pipelines.registration.pointcloud import SequencePointcloudRegistrationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_TRACK_DIR = \"/home/docker_opr/Datasets/ITLP-Campus-data/subsampled_data/indoor/00_2023-10-25-night\"\n",
    "QUERY_TRACK_DIR = \"/home/docker_opr/Datasets/ITLP-Campus-data/subsampled_data/indoor/01_2023-11-09-twilight\"\n",
    "\n",
    "REGISTRATION_MODEL_CONFIG_PATH = \"../../configs/model/registration/geotransformer_kitti.yaml\"\n",
    "REGISTRATION_WEIGHTS_PATH = \"../../weights/registration/geotransformer_kitti.pth\"\n",
    "\n",
    "SENSOR_SUITE = [\"front_cam\", \"back_cam\", \"lidar\"]\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "MODEL_CONFIG_PATH = \"../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "WEIGHTS_PATH = \"../weights/place_recognition/multi-image_lidar_late-fusion_nclt.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return dist_error, angle_error\n",
    "\n",
    "def compute_translation_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    gt_trans = gt_pose[:3, 3]\n",
    "    pred_trans = pred_pose[:3, 3]\n",
    "    error = np.linalg.norm(gt_trans - pred_trans)\n",
    "    return error\n",
    "\n",
    "def compute_rotation_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    gt_rot = Rotation.from_matrix(gt_pose[:3, :3])\n",
    "    pred_rot = Rotation.from_matrix(pred_pose[:3, :3])\n",
    "    error = Rotation.inv(gt_rot) * pred_rot\n",
    "    error = error.as_euler('xyz', degrees=True)\n",
    "    error = np.linalg.norm(error)\n",
    "    return error\n",
    "\n",
    "def compute_absolute_pose_error(gt_pose, pred_pose):\n",
    "    \"\"\"For the 4x4 pose matrices.\"\"\"\n",
    "    rotation_error = compute_rotation_error(gt_pose, pred_pose)\n",
    "    translation_error = compute_translation_error(gt_pose, pred_pose)\n",
    "    return rotation_error, translation_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dataset = ITLPCampus(\n",
    "    dataset_root=DATABASE_TRACK_DIR,\n",
    "    sensors=[\"front_cam\", \"back_cam\", \"lidar\"],\n",
    "    mink_quantization_size=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dataloader = DataLoader(\n",
    "    db_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=db_dataset.collate_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = OmegaConf.load(MODEL_CONFIG_PATH)\n",
    "model = instantiate(model_config)\n",
    "model.load_state_dict(torch.load(WEIGHTS_PATH))\n",
    "model = model.to(DEVICE)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "geotransformer = instantiate(OmegaConf.load(REGISTRATION_MODEL_CONFIG_PATH))\n",
    "\n",
    "registration_pipe = SequencePointcloudRegistrationPipeline(\n",
    "    model=geotransformer,\n",
    "    model_weights_path=REGISTRATION_WEIGHTS_PATH,\n",
    "    device=\"cuda\",  # the GeoTransformer currently only supports CUDA\n",
    "    voxel_downsample_size=0.5,  # recommended for geotransformer_kitti configuration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = PlaceRecognitionPipeline(\n",
    "    database_dir=DATABASE_TRACK_DIR,\n",
    "    model=model,\n",
    "    model_weights_path=WEIGHTS_PATH,\n",
    "    device=DEVICE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dataset = ITLPCampus(\n",
    "    dataset_root=QUERY_TRACK_DIR,\n",
    "    sensors=SENSOR_SUITE,\n",
    "    mink_quantization_size=0.5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1309 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1309/1309 [00:51<00:00, 25.42it/s]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "PR_THRESHOLD = 25.0\n",
    "\n",
    "db_matches = {}\n",
    "\n",
    "pr_matches = []\n",
    "dist_errors = []\n",
    "angle_errors = []\n",
    "times = []\n",
    "\n",
    "for i in tqdm(range(1, len(query_dataset)), total=len(query_dataset)-1):\n",
    "    query = query_dataset[i]\n",
    "    output_idx = pipe.infer(query)[\"idx\"]\n",
    "    db_matches[i] = output_idx\n",
    "\n",
    "del pipe\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dataset = ITLPCampus(\n",
    "    dataset_root=QUERY_TRACK_DIR,\n",
    "    sensors=SENSOR_SUITE,\n",
    "    mink_quantization_size=0.5,\n",
    "    max_point_distance=20,\n",
    ")\n",
    "\n",
    "db_dataset = ITLPCampus(\n",
    "    dataset_root=DATABASE_TRACK_DIR,\n",
    "    sensors=SENSOR_SUITE,\n",
    "    mink_quantization_size=0.5,\n",
    "    max_point_distance=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(1, len(query_dataset)), total=len(query_dataset)-1):\n",
    "    query = query_dataset[i]\n",
    "    query_seq = [query_dataset[i-1][\"pointcloud_lidar_coords\"], query_dataset[i][\"pointcloud_lidar_coords\"]]\n",
    "    output_idx = db_matches[i]\n",
    "    db_match = db_dataset[output_idx]\n",
    "    torch.cuda.empty_cache()\n",
    "    db_pose = pose_to_matrix(db_match[\"pose\"])\n",
    "    db_pc = db_match[\"pointcloud_lidar_coords\"]\n",
    "    t = time()\n",
    "    estimated_transformation = registration_pipe.infer(query_seq, db_pc)\n",
    "    times.append(time() - t)\n",
    "    optimized_pose = db_pose @ estimated_transformation\n",
    "    torch.cuda.empty_cache()\n",
    "    angle_error, dist_error = compute_absolute_pose_error(optimized_pose, pose_to_matrix(query[\"pose\"]))\n",
    "    pr_matches.append(dist_error < PR_THRESHOLD)\n",
    "    dist_errors.append(dist_error)\n",
    "    angle_errors.append(angle_error)\n",
    "\n",
    "times = times[1:]  # the first query is always slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 68.63\n",
      "Mean distance error: 47.38, mean angle error: 5.54\n",
      "Median distance error: 1.30, median angle error: 2.84\n"
     ]
    }
   ],
   "source": [
    "print(f\"Recall@1: {(np.mean(pr_matches))*100:.2f}\")\n",
    "print(f\"Mean distance error: {np.mean(dist_errors):.2f}, mean angle error: {np.mean(angle_errors):.2f}\")\n",
    "print(f\"Median distance error: {np.median(dist_errors):.2f}, median angle error: {np.median(angle_errors):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean inference time: {np.mean(times)*1000:.2f} ms, median inference time: {np.median(times)*1000:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
