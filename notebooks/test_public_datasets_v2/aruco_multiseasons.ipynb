{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import cv2\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.spatial.transform import Rotation\n",
    "from geotransformer.utils.pointcloud import get_transform_from_rotation_translation\n",
    "\n",
    "from opr.datasets.itlp import ITLPCampus\n",
    "from opr.pipelines.localization import ArucoLocalizationPipeline\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline\n",
    "from opr.pipelines.registration import PointcloudRegistrationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return angle_error, dist_error\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2\"\n",
    "SENSOR_SUITE = [\"front_cam\", \"back_cam\", \"lidar\"]\n",
    "\n",
    "TRACK_LIST = [\n",
    "    \"00_2023-02-10\",\n",
    "    \"03_2023-04-11\",\n",
    "    \"05_2023-08-15-day\",\n",
    "    \"07_2023-10-04-day\",\n",
    "]\n",
    "\n",
    "SEASON_MAPPING = {\n",
    "    \"00_2023-02-10\": \"winter\",\n",
    "    \"03_2023-04-11\": \"spring\",\n",
    "    \"05_2023-08-15-day\": \"summer\",\n",
    "    \"07_2023-10-04-day\": \"fall\",\n",
    "}\n",
    "\n",
    "print(\"Test track list:\")\n",
    "print(TRACK_LIST)\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_dataset = ITLPCampus(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    csv_file=\"aruco_full_test.csv\",\n",
    "    sensors=SENSOR_SUITE,\n",
    ")\n",
    "test_db_dataset = ITLPCampus(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    csv_file=\"full_test.csv\",\n",
    "    sensors=SENSOR_SUITE,\n",
    ")\n",
    "test_db_dataset.dataset_df = test_db_dataset.dataset_df[test_db_dataset.dataset_df[\"track\"].isin(TRACK_LIST)]\n",
    "test_db_dataset.dataset_df.reset_index(inplace=True)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    test_db_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=test_db_dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "PR_WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_lidar_late-fusion_itlp-finetune.pth\"\n",
    "\n",
    "pr_model_config = OmegaConf.load(PR_MODEL_CONFIG_PATH)\n",
    "pr_model = instantiate(pr_model_config)\n",
    "pr_model.load_state_dict(torch.load(PR_WEIGHTS_PATH))\n",
    "pr_model = pr_model.to(DEVICE)\n",
    "pr_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        final_descriptor = pr_model(batch)[\"final_descriptor\"]\n",
    "        descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "descriptors = np.concatenate(descriptors, axis=0)\n",
    "\n",
    "dataset_df = test_db_dataset.dataset_df\n",
    "for track, indices in dataset_df.groupby(\"track\").groups.items():\n",
    "    track_descriptors = descriptors[indices]\n",
    "    track_index = faiss.IndexFlatL2(track_descriptors.shape[1])\n",
    "    track_index.add(track_descriptors)\n",
    "    faiss.write_index(track_index, f\"{DATASET_ROOT}/{track}/index.faiss\")\n",
    "    print(f\"Saved index {DATASET_ROOT}/{track}/index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_metadata = {\n",
    "    \"front_cam_intrinsics\": [[683.6199340820312, 0.0, 615.1160278320312],\n",
    "                             [0.0, 683.6199340820312, 345.32354736328125],\n",
    "                             [0.0, 0.0, 1.0]],\n",
    "    \"front_cam_distortion\": [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    \"front_cam2baselink\": [-0.2388, 0.06, 0.75, -0.5, 0.49999999999755174, -0.5, 0.5000000000024483],\n",
    "    \"back_cam_intrinsics\": [[910.4178466796875, 0.0, 648.44140625],\n",
    "                            [0.0, 910.4166870117188, 354.0118408203125],\n",
    "                            [0.0, 0.0, 1.0]],\n",
    "    \"back_cam_distortion\": [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    \"back_cam2baselink\": [-0.3700594606670597, -0.006647301538708517, 0.7427924789987381, -0.4981412857230513, -0.4907829006275322, 0.5090864815669471, 0.5018149813673275]\n",
    "}\n",
    "\n",
    "aruco_metadata = {\n",
    "    \"aruco_type\": cv2.aruco.DICT_4X4_250,\n",
    "    \"aruco_size\": 0.2,\n",
    "    \"aruco_gt_pose_by_id\": {\n",
    "        0: [-23.76325316, 16.94296093, 1.51796168, 0.25454437, 0.65070725, 0.6526984, 0.29286864],\n",
    "        2: [-8.81475372, -12.47510287, 1.75787052, 0.61022095, -0.21494468, -0.21004688, 0.73301397],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRATION_MODEL_CONFIG_PATH = \"../../configs/model/registration/hregnet_light_feats.yaml\"\n",
    "REGISTRATION_WEIGHTS_PATH = \"../../weights/registration/hregnet_light_feats_nuscenes.pth\"\n",
    "\n",
    "reg_model_config = OmegaConf.load(REGISTRATION_MODEL_CONFIG_PATH)\n",
    "reg_model = instantiate(reg_model_config)\n",
    "reg_model.load_state_dict(torch.load(REGISTRATION_WEIGHTS_PATH))\n",
    "reg_model = reg_model.to(DEVICE)\n",
    "reg_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECALL_THRESHOLD = 25.0\n",
    "\n",
    "all_reg_recalls_aruco = {}\n",
    "all_mean_reg_rotation_errors_aruco = {}\n",
    "all_mean_reg_translation_errors_aruco = {}\n",
    "all_median_reg_rotation_errors_aruco = {}\n",
    "all_median_reg_translation_errors_aruco = {}\n",
    "all_times_aruco = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for db_track in TRACK_LIST:\n",
    "    pr_pipe = PlaceRecognitionPipeline(\n",
    "        database_dir=Path(DATASET_ROOT) / db_track,\n",
    "        model=pr_model,\n",
    "        model_weights_path=PR_WEIGHTS_PATH,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    for query_track in TRACK_LIST:\n",
    "        if db_track == query_track:\n",
    "            continue\n",
    "\n",
    "        reg_pipe = PointcloudRegistrationPipeline(\n",
    "            model=reg_model,\n",
    "            model_weights_path=REGISTRATION_WEIGHTS_PATH,\n",
    "            device=DEVICE,\n",
    "            voxel_downsample_size=0.3,\n",
    "            num_points_downsample=8192,\n",
    "        )\n",
    "        loc_pipe = ArucoLocalizationPipeline(\n",
    "            place_recognition_pipeline=pr_pipe,\n",
    "            registration_pipeline=reg_pipe,\n",
    "            precomputed_reg_feats=True,\n",
    "            pointclouds_subdir=\"lidar\",\n",
    "            aruco_metadata=aruco_metadata,\n",
    "            camera_metadata=camera_metadata,\n",
    "            fastest=False,\n",
    "            use_first_marker=True\n",
    "        )\n",
    "\n",
    "        query_dataset = copy.deepcopy(test_query_dataset)\n",
    "        query_dataset.dataset_df = query_dataset.dataset_df[query_dataset.dataset_df[\"track\"] == query_track].reset_index(drop=True)\n",
    "        query_df = query_dataset.dataset_df\n",
    "        ###\n",
    "        # specific for aruco\n",
    "        query_dataset.image_transform = lambda x: x\n",
    "\n",
    "        db_dataset = copy.deepcopy(test_db_dataset)\n",
    "        db_dataset.dataset_df = db_dataset.dataset_df[db_dataset.dataset_df[\"track\"] == db_track].reset_index(drop=True)\n",
    "        db_df = db_dataset.dataset_df\n",
    "        ###\n",
    "        # specific for aruco\n",
    "        db_dataset.image_transform = lambda x: x\n",
    "        warmup_sample = db_dataset[0]\n",
    "\n",
    "        loc_pipe.pr_pipe.database_df = db_df\n",
    "        loc_pipe.database_df = db_df\n",
    "\n",
    "        reg_matches_aruco = []\n",
    "        reg_rotation_errors_aruco = []\n",
    "        reg_translation_errors_aruco = []\n",
    "        times_aruco = []\n",
    "\n",
    "        # fake launch to run first long call of torch model\n",
    "        _ = loc_pipe.loc_part(warmup_sample)\n",
    "\n",
    "        for q_i, query in tqdm(enumerate(query_dataset)):\n",
    "            query_pose = query_df.iloc[q_i][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "            start = time()\n",
    "            output = loc_pipe.infer(query)\n",
    "            torch.cuda.current_stream().synchronize()\n",
    "            step_time = time() - start\n",
    "            times_aruco.append(step_time)\n",
    "\n",
    "            estimated_pose = output[\"pose_by_aruco\"] if output[\"pose_by_aruco\"] is not None else output[\"pose_by_place_recognition\"]\n",
    "\n",
    "            reg_rotation_error_aruco, reg_translation_error_aruco = compute_error(estimated_pose, query_pose)\n",
    "            reg_correct_aruco = reg_translation_error_aruco < RECALL_THRESHOLD\n",
    "            reg_matches_aruco.append(reg_correct_aruco)\n",
    "            reg_rotation_errors_aruco.append(reg_rotation_error_aruco)\n",
    "            reg_translation_errors_aruco.append(reg_translation_error_aruco)\n",
    "\n",
    "        key_str = f\"DB {SEASON_MAPPING[db_track]}, Query {SEASON_MAPPING[query_track]}\"\n",
    "        all_reg_recalls_aruco[key_str] = np.nanmean(reg_matches_aruco)\n",
    "        all_mean_reg_rotation_errors_aruco[key_str] = np.nanmean(reg_rotation_errors_aruco)\n",
    "        all_mean_reg_translation_errors_aruco[key_str] = np.nanmean(reg_translation_errors_aruco)\n",
    "        all_median_reg_rotation_errors_aruco[key_str] = np.nanmedian(reg_rotation_errors_aruco)\n",
    "        all_median_reg_translation_errors_aruco[key_str] = np.nanmedian(reg_translation_errors_aruco)\n",
    "        all_times_aruco.extend(times_aruco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall@1:\")\n",
    "for key, value in all_reg_recalls_aruco.items():\n",
    "    print(f\"{key}: {value*100:.2f}\")\n",
    "\n",
    "print(f\"Mean: {np.nanmean(list(all_reg_recalls_aruco.values()))*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Median RRE:\")\n",
    "for key, value in all_median_reg_rotation_errors_aruco.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "\n",
    "print(f\"Mean: {np.nanmean(list(all_median_reg_rotation_errors_aruco.values())):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Median RTE:\")\n",
    "for key, value in all_median_reg_translation_errors_aruco.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "\n",
    "\n",
    "print(f\"Mean: {np.nanmean(list(all_median_reg_translation_errors_aruco.values())):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean inference time: {np.nanmean(all_times_aruco) * 1000:.2f} ms\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
