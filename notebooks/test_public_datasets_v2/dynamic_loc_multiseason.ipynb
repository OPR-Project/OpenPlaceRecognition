{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import cv2\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.spatial.transform import Rotation\n",
    "from geotransformer.utils.pointcloud import get_transform_from_rotation_translation\n",
    "\n",
    "from opr.datasets.itlp import ITLPCampus\n",
    "from opr.pipelines.localization import LocalizationPipeline\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline\n",
    "from opr.pipelines.registration import PointcloudRegistrationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2\"\n",
    "SENSOR_SUITE = [\"front_cam\", \"back_cam\", \"lidar\"]\n",
    "\n",
    "TRACK_LIST = [\n",
    "    \"00_2023-02-10\",\n",
    "    \"03_2023-04-11\",\n",
    "    \"05_2023-08-15-day\",\n",
    "    \"07_2023-10-04-day\",\n",
    "]\n",
    "\n",
    "SEASON_MAPPING = {\n",
    "    \"00_2023-02-10\": \"winter\",\n",
    "    \"03_2023-04-11\": \"spring\",\n",
    "    \"05_2023-08-15-day\": \"summer\",\n",
    "    \"07_2023-10-04-day\": \"fall\",\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 18\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 18) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return angle_error, dist_error\n",
    "\n",
    "def inference():\n",
    "    for db_track in TRACK_LIST:\n",
    "        pr_pipe = PlaceRecognitionPipeline(\n",
    "            database_dir=Path(DATASET_ROOT) / db_track,\n",
    "            model=pr_model,\n",
    "            model_weights_path=PR_WEIGHTS_PATH,\n",
    "            device=DEVICE,\n",
    "        )\n",
    "        for query_track in TRACK_LIST:\n",
    "            if db_track == query_track:\n",
    "                continue\n",
    "\n",
    "            reg_pipe = PointcloudRegistrationPipeline(\n",
    "                model=reg_model,\n",
    "                model_weights_path=REGISTRATION_WEIGHTS_PATH,\n",
    "                device=DEVICE,\n",
    "                voxel_downsample_size=0.3,\n",
    "                num_points_downsample=8192,\n",
    "            )\n",
    "            loc_pipe = LocalizationPipeline(\n",
    "                place_recognition_pipeline=pr_pipe,\n",
    "                registration_pipeline=reg_pipe,\n",
    "                precomputed_reg_feats=True,\n",
    "                pointclouds_subdir=\"lidar\"\n",
    "            )\n",
    "\n",
    "            query_dataset = copy.deepcopy(dataset)\n",
    "            query_dataset.dataset_df = query_dataset.dataset_df[query_dataset.dataset_df[\"track\"] == query_track].reset_index(drop=True)\n",
    "            query_df = query_dataset.dataset_df\n",
    "\n",
    "            db_dataset = copy.deepcopy(dataset)\n",
    "            db_dataset.dataset_df = db_dataset.dataset_df[db_dataset.dataset_df[\"track\"] == db_track].reset_index(drop=True)\n",
    "            db_df = db_dataset.dataset_df\n",
    "\n",
    "            loc_pipe.pr_pipe.database_df = db_df\n",
    "            loc_pipe.database_df = db_df\n",
    "\n",
    "            reg_matches = []\n",
    "            reg_rotation_errors = []\n",
    "            reg_translation_errors = []\n",
    "            times = []\n",
    "\n",
    "            for q_i, query in tqdm(enumerate(query_dataset)):\n",
    "                query_pose = query_df.iloc[q_i][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "                start = time()\n",
    "                estimated_pose = loc_pipe.infer(query)[\"estimated_pose\"]\n",
    "                torch.cuda.current_stream().synchronize()\n",
    "                step_time = time() - start\n",
    "                times.append(step_time)\n",
    "\n",
    "                reg_rotation_error, reg_translation_error = compute_error(estimated_pose, query_pose)\n",
    "                reg_correct = reg_translation_error < RECALL_THRESHOLD\n",
    "                reg_matches.append(reg_correct)\n",
    "                reg_rotation_errors.append(reg_rotation_error)\n",
    "                reg_translation_errors.append(reg_translation_error)\n",
    "\n",
    "            key_str = f\"DB {SEASON_MAPPING[db_track]}, Query {SEASON_MAPPING[query_track]}\"\n",
    "            all_reg_recalls[key_str] = np.nanmean(reg_matches)\n",
    "            all_mean_reg_rotation_errors[key_str] = np.nanmean(reg_rotation_errors)\n",
    "            all_mean_reg_translation_errors[key_str] = np.nanmean(reg_translation_errors)\n",
    "            all_median_reg_rotation_errors[key_str] = np.nanmedian(reg_rotation_errors)\n",
    "            all_median_reg_translation_errors[key_str] = np.nanmedian(reg_translation_errors)\n",
    "            all_times.extend(times[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from opr.datasets.augmentations import DefaultImageTransform\n",
    "\n",
    "class ToTensorTransform:\n",
    "    def __init__(self):\n",
    "        transform_list = [ToTensorV2()]\n",
    "        self.transform = A.Compose(transform_list)\n",
    "\n",
    "    def __call__(self, img: np.ndarray):\n",
    "        \"\"\"Applies transformations to the given image.\"\"\"\n",
    "        return self.transform(image=img)[\"image\"]\n",
    "\n",
    "dataset = ITLPCampus(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    csv_file=\"full_test.csv\",\n",
    "    sensors=SENSOR_SUITE,\n",
    "    load_semantics=True,\n",
    "    exclude_dynamic_classes=True,\n",
    "    image_transform=ToTensorTransform(),\n",
    "    semantic_transform=ToTensorTransform(),\n",
    "    late_image_transform=DefaultImageTransform(resize=(320, 192), train=False)\n",
    ")\n",
    "dataset.dataset_df = dataset.dataset_df[dataset.dataset_df[\"track\"].isin(TRACK_LIST)]\n",
    "dataset.dataset_df.reset_index(inplace=True)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRATION_MODEL_CONFIG_PATH = \"../../configs/model/registration/hregnet_light_feats.yaml\"\n",
    "REGISTRATION_WEIGHTS_PATH = \"../../weights/registration/hregnet_light_feats_nuscenes.pth\"\n",
    "reg_model_config = OmegaConf.load(REGISTRATION_MODEL_CONFIG_PATH)\n",
    "reg_model = instantiate(reg_model_config)\n",
    "reg_model.load_state_dict(torch.load(REGISTRATION_WEIGHTS_PATH))\n",
    "reg_model = reg_model.to(DEVICE)\n",
    "reg_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIPT finetune\n",
    "\n",
    "all_reg_recalls = {}\n",
    "all_mean_reg_rotation_errors = {}\n",
    "all_mean_reg_translation_errors = {}\n",
    "all_median_reg_rotation_errors = {}\n",
    "all_median_reg_translation_errors = {}\n",
    "all_times = []\n",
    "RECALL_THRESHOLD = 25.0\n",
    "\n",
    "PR_MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "PR_WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_lidar_late-fusion_itlp-finetune.pth\"\n",
    "pr_model_config = OmegaConf.load(PR_MODEL_CONFIG_PATH)\n",
    "pr_model = instantiate(pr_model_config)\n",
    "pr_model.load_state_dict(torch.load(PR_WEIGHTS_PATH))\n",
    "pr_model = pr_model.to(DEVICE)\n",
    "pr_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:58<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/00_2023-02-10/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/03_2023-04-11/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/05_2023-08-15-day/index.faiss\n",
      "Saved index /home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2/07_2023-10-04-day/index.faiss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "descriptors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        final_descriptor = pr_model(batch)[\"final_descriptor\"]\n",
    "        descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "descriptors = np.concatenate(descriptors, axis=0)\n",
    "\n",
    "dataset_df = dataset.dataset_df\n",
    "for track, indices in dataset_df.groupby(\"track\").groups.items():\n",
    "    track_descriptors = descriptors[indices]\n",
    "    track_index = faiss.IndexFlatL2(track_descriptors.shape[1])\n",
    "    track_index.add(track_descriptors)\n",
    "    faiss.write_index(track_index, f\"{DATASET_ROOT}/{track}/index.faiss\")\n",
    "    print(f\"Saved index {DATASET_ROOT}/{track}/index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "136it [00:52,  2.59it/s]\n",
      "152it [00:49,  3.08it/s]\n",
      "152it [00:49,  3.04it/s]\n",
      "139it [00:45,  3.03it/s]\n",
      "152it [00:48,  3.11it/s]\n",
      "152it [00:48,  3.11it/s]\n",
      "139it [00:46,  2.99it/s]\n",
      "136it [00:43,  3.12it/s]\n",
      "152it [00:49,  3.05it/s]\n",
      "139it [00:45,  3.03it/s]\n",
      "136it [00:44,  3.08it/s]\n",
      "152it [00:49,  3.09it/s]\n"
     ]
    }
   ],
   "source": [
    "inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1:\n",
      "DB winter, Query spring: 100.00\n",
      "DB winter, Query summer: 92.11\n",
      "DB winter, Query fall: 99.34\n",
      "DB spring, Query winter: 99.28\n",
      "DB spring, Query summer: 96.05\n",
      "DB spring, Query fall: 99.34\n",
      "DB summer, Query winter: 94.96\n",
      "DB summer, Query spring: 91.91\n",
      "DB summer, Query fall: 100.00\n",
      "DB fall, Query winter: 96.40\n",
      "DB fall, Query spring: 94.85\n",
      "DB fall, Query summer: 100.00\n",
      "Mean: 97.02\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall@1:\")\n",
    "for key, value in all_reg_recalls.items():\n",
    "    print(f\"{key}: {value*100:.2f}\")\n",
    "\n",
    "print(f\"Mean: {np.nanmean(list(all_reg_recalls.values()))*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median RRE:\n",
      "DB winter, Query spring: 1.78\n",
      "DB winter, Query summer: 7.25\n",
      "DB winter, Query fall: 4.43\n",
      "DB spring, Query winter: 1.75\n",
      "DB spring, Query summer: 5.76\n",
      "DB spring, Query fall: 4.44\n",
      "DB summer, Query winter: 7.25\n",
      "DB summer, Query spring: 5.58\n",
      "DB summer, Query fall: 4.91\n",
      "DB fall, Query winter: 4.13\n",
      "DB fall, Query spring: 4.65\n",
      "DB fall, Query summer: 4.27\n",
      "Mean: 4.68\n"
     ]
    }
   ],
   "source": [
    "print(\"Median RRE:\")\n",
    "for key, value in all_median_reg_rotation_errors.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "\n",
    "print(f\"Mean: {np.nanmean(list(all_median_reg_rotation_errors.values())):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median RTE:\n",
      "DB winter, Query spring: 1.05\n",
      "DB winter, Query summer: 4.25\n",
      "DB winter, Query fall: 4.37\n",
      "DB spring, Query winter: 0.73\n",
      "DB spring, Query summer: 3.29\n",
      "DB spring, Query fall: 4.06\n",
      "DB summer, Query winter: 3.82\n",
      "DB summer, Query spring: 3.56\n",
      "DB summer, Query fall: 2.99\n",
      "DB fall, Query winter: 4.18\n",
      "DB fall, Query spring: 4.49\n",
      "DB fall, Query summer: 3.17\n",
      "Mean: 3.33\n"
     ]
    }
   ],
   "source": [
    "print(\"Median RTE:\")\n",
    "for key, value in all_median_reg_translation_errors.items():\n",
    "    print(f\"{key}: {value:.2f}\")\n",
    "\n",
    "\n",
    "print(f\"Mean: {np.nanmean(list(all_median_reg_translation_errors.values())):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference time: 119.42 ms\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean inference time: {np.nanmean(all_times) * 1000:.2f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
