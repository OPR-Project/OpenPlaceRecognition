{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from time import time\n",
    "\n",
    "import cv2\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.spatial.transform import Rotation\n",
    "from geotransformer.utils.pointcloud import get_transform_from_rotation_translation\n",
    "\n",
    "from opr.datasets.itlp import ITLPCampus\n",
    "from opr.pipelines.localization import ArucoLocalizationPipeline\n",
    "from opr.pipelines.place_recognition import PlaceRecognitionPipeline\n",
    "from opr.pipelines.registration import PointcloudRegistrationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_to_matrix(pose):\n",
    "    \"\"\"From the 6D poses in the [tx ty tz qx qy qz qw] format to 4x4 pose matrices.\"\"\"\n",
    "    position = pose[:3]\n",
    "    orientation_quat = pose[3:]\n",
    "    rotation = Rotation.from_quat(orientation_quat)\n",
    "    pose_matrix = np.eye(4)\n",
    "    pose_matrix[:3,:3] = rotation.as_matrix()\n",
    "    pose_matrix[:3,3] = position\n",
    "    return pose_matrix\n",
    "\n",
    "def compute_error(estimated_pose, gt_pose):\n",
    "    \"\"\"For the 6D poses in the [tx ty tz qx qy qz qw] format.\"\"\"\n",
    "    estimated_pose = pose_to_matrix(estimated_pose)\n",
    "    gt_pose = pose_to_matrix(gt_pose)\n",
    "    error_pose = np.linalg.inv(estimated_pose) @ gt_pose\n",
    "    dist_error = np.sum(error_pose[:3, 3]**2) ** 0.5\n",
    "    r = Rotation.from_matrix(error_pose[:3, :3])\n",
    "    rotvec = r.as_rotvec()\n",
    "    angle_error = (np.sum(rotvec**2)**0.5) * 180 / np.pi\n",
    "    angle_error = abs(90 - abs(angle_error-90))\n",
    "    return angle_error, dist_error\n",
    "\n",
    "def inference():\n",
    "    for db_track in TRACK_LIST:\n",
    "        pr_pipe = PlaceRecognitionPipeline(\n",
    "            database_dir=Path(DATASET_ROOT) / db_track,\n",
    "            model=pr_model,\n",
    "            model_weights_path=PR_WEIGHTS_PATH,\n",
    "            device=DEVICE,\n",
    "        )\n",
    "        for query_track in TRACK_LIST:\n",
    "            if db_track == query_track:\n",
    "                continue\n",
    "\n",
    "            reg_pipe = PointcloudRegistrationPipeline(\n",
    "                model=reg_model,\n",
    "                model_weights_path=REGISTRATION_WEIGHTS_PATH,\n",
    "                device=DEVICE,\n",
    "                voxel_downsample_size=0.3,\n",
    "                num_points_downsample=8192,\n",
    "            )\n",
    "            loc_pipe = ArucoLocalizationPipeline(\n",
    "                place_recognition_pipeline=pr_pipe,\n",
    "                registration_pipeline=reg_pipe,\n",
    "                precomputed_reg_feats=True,\n",
    "                pointclouds_subdir=\"lidar\",\n",
    "                aruco_metadata=aruco_metadata,\n",
    "                camera_metadata=camera_metadata,\n",
    "                fastest=True,\n",
    "                use_first_marker=True\n",
    "            )\n",
    "\n",
    "            query_dataset = copy.deepcopy(test_query_dataset)\n",
    "            query_dataset.dataset_df = query_dataset.dataset_df[query_dataset.dataset_df[\"track\"] == query_track].reset_index(drop=True)\n",
    "            query_df = query_dataset.dataset_df\n",
    "            ###\n",
    "            # specific for aruco\n",
    "            query_dataset.image_transform = lambda x: x\n",
    "\n",
    "            db_dataset = copy.deepcopy(test_db_dataset)\n",
    "            db_dataset.dataset_df = db_dataset.dataset_df[db_dataset.dataset_df[\"track\"] == db_track].reset_index(drop=True)\n",
    "            db_df = db_dataset.dataset_df\n",
    "            ###\n",
    "            # specific for aruco\n",
    "            db_dataset.image_transform = lambda x: x\n",
    "            warmup_sample = db_dataset[0]\n",
    "\n",
    "            loc_pipe.pr_pipe.database_df = db_df\n",
    "            loc_pipe.database_df = db_df\n",
    "\n",
    "            reg_matches_aruco = []\n",
    "            reg_rotation_errors_aruco = []\n",
    "            reg_translation_errors_aruco = []\n",
    "            times_aruco = []\n",
    "\n",
    "            # fake launch to run first long call of torch model\n",
    "            _ = loc_pipe.loc_part(warmup_sample)\n",
    "\n",
    "            for q_i, query in tqdm(enumerate(query_dataset)):\n",
    "                query_pose = query_df.iloc[q_i][[\"tx\", \"ty\", \"tz\", \"qx\", \"qy\", \"qz\", \"qw\"]].to_numpy()\n",
    "                start = time()\n",
    "                output = loc_pipe.infer(query)\n",
    "                torch.cuda.current_stream().synchronize()\n",
    "                step_time = time() - start\n",
    "                times_aruco.append(step_time)\n",
    "\n",
    "                estimated_pose = output[\"pose_by_aruco\"] if output[\"pose_by_aruco\"] is not None else output[\"pose_by_place_recognition\"]\n",
    "\n",
    "                reg_rotation_error_aruco, reg_translation_error_aruco = compute_error(estimated_pose, query_pose)\n",
    "                reg_correct_aruco = reg_translation_error_aruco < RECALL_THRESHOLD\n",
    "                reg_matches_aruco.append(reg_correct_aruco)\n",
    "                reg_rotation_errors_aruco.append(reg_rotation_error_aruco)\n",
    "                reg_translation_errors_aruco.append(reg_translation_error_aruco)\n",
    "\n",
    "            all_reg_recalls_aruco.append(np.nanmean(reg_matches_aruco))\n",
    "            all_mean_reg_rotation_errors_aruco.append(np.nanmean(reg_rotation_errors_aruco))\n",
    "            all_mean_reg_translation_errors_aruco.append(np.nanmean(reg_translation_errors_aruco))\n",
    "            all_median_reg_rotation_errors_aruco.append(np.nanmedian(reg_rotation_errors_aruco))\n",
    "            all_median_reg_translation_errors_aruco.append(np.nanmedian(reg_translation_errors_aruco))\n",
    "            all_times_aruco.extend(times_aruco)\n",
    "\n",
    "    results_str_aruco = f\"\"\"Average REG Recall@1:  {np.nanmean(all_reg_recalls_aruco)*100:.2f}\n",
    "\n",
    "        Average Mean RRE REG:  {np.nanmean(all_mean_reg_rotation_errors_aruco):.2f}\n",
    "        Average Mean RTE REG:  {np.nanmean(all_mean_reg_translation_errors_aruco):.2f}\n",
    "        Average Median RRE REG:  {np.nanmean(all_median_reg_rotation_errors_aruco):.2f}\n",
    "        Average Median RTE REG:  {np.nanmean(all_median_reg_translation_errors_aruco):.2f}\n",
    "\n",
    "        Mean inference time:     {np.nanmean(all_times_aruco)*1000:.2f} ms\n",
    "        \"\"\"\n",
    "    return results_str_aruco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/docker_opr/Datasets/OpenPlaceRecognition/itlp_campus_outdoor_part2\"\n",
    "SENSOR_SUITE = [\"front_cam\", \"back_cam\", \"lidar\"]\n",
    "TRACK_LIST = sorted([str(subdir.name) for subdir in Path(DATASET_ROOT).iterdir() if subdir.is_dir()])[5:]\n",
    "\n",
    "print(\"Test track list:\")\n",
    "print(TRACK_LIST)\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_db_dataset = ITLPCampus(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    subset=\"test\",\n",
    "    csv_file=\"test.csv\",\n",
    "    sensors=SENSOR_SUITE,\n",
    ")\n",
    "test_db_dataset.dataset_df = test_db_dataset.dataset_df[test_db_dataset.dataset_df[\"track\"].isin(TRACK_LIST)]\n",
    "test_db_dataset.dataset_df.reset_index(inplace=True)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    test_db_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=test_db_dataset.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        final_descriptor = pr_model(batch)[\"final_descriptor\"]\n",
    "        descriptors.append(final_descriptor.detach().cpu().numpy())\n",
    "descriptors = np.concatenate(descriptors, axis=0)\n",
    "\n",
    "dataset_df = test_db_dataset.dataset_df\n",
    "for track, indices in dataset_df.groupby(\"track\").groups.items():\n",
    "    track_descriptors = descriptors[indices]\n",
    "    track_index = faiss.IndexFlatL2(track_descriptors.shape[1])\n",
    "    track_index.add(track_descriptors)\n",
    "    faiss.write_index(track_index, f\"{DATASET_ROOT}/{track}/index.faiss\")\n",
    "    print(f\"Saved index {DATASET_ROOT}/{track}/index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "camera_metadata = {\n",
    "    \"front_cam_intrinsics\": [[683.6199340820312, 0.0, 615.1160278320312],\n",
    "                             [0.0, 683.6199340820312, 345.32354736328125],\n",
    "                             [0.0, 0.0, 1.0]],\n",
    "    \"front_cam_distortion\": [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    \"front_cam2baselink\": [-0.2388, 0.06, 0.75, -0.5, 0.49999999999755174, -0.5, 0.5000000000024483],\n",
    "    \"back_cam_intrinsics\": [[910.4178466796875, 0.0, 648.44140625],\n",
    "                            [0.0, 910.4166870117188, 354.0118408203125],\n",
    "                            [0.0, 0.0, 1.0]],\n",
    "    \"back_cam_distortion\": [0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    \"back_cam2baselink\": [-0.3700594606670597, -0.006647301538708517, 0.7427924789987381, -0.4981412857230513, -0.4907829006275322, 0.5090864815669471, 0.5018149813673275]\n",
    "}\n",
    "\n",
    "aruco_metadata = {\n",
    "    \"aruco_type\": cv2.aruco.DICT_4X4_250,\n",
    "    \"aruco_size\": 0.2,\n",
    "    \"aruco_gt_pose_by_id\": {\n",
    "        0: [-23.76325316, 16.94296093, 1.51796168, 0.25454437, 0.65070725, 0.6526984, 0.29286864],\n",
    "        2: [-8.81475372, -12.47510287, 1.75787052, 0.61022095, -0.21494468, -0.21004688, 0.73301397],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRATION_MODEL_CONFIG_PATH = \"../../configs/model/registration/hregnet_light_feats.yaml\"\n",
    "REGISTRATION_WEIGHTS_PATH = \"../../weights/registration/hregnet_light_feats_nuscenes.pth\"\n",
    "\n",
    "reg_model_config = OmegaConf.load(REGISTRATION_MODEL_CONFIG_PATH)\n",
    "reg_model = instantiate(reg_model_config)\n",
    "reg_model.load_state_dict(torch.load(REGISTRATION_WEIGHTS_PATH))\n",
    "reg_model = reg_model.to(DEVICE)\n",
    "reg_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCLT\n",
    "\n",
    "all_reg_recalls_aruco = []\n",
    "all_mean_reg_rotation_errors_aruco = []\n",
    "all_mean_reg_translation_errors_aruco = []\n",
    "all_median_reg_rotation_errors_aruco = []\n",
    "all_median_reg_translation_errors_aruco = []\n",
    "all_times_aruco = []\n",
    "RECALL_THRESHOLD = 25.0\n",
    "\n",
    "PR_MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "PR_WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_lidar_late-fusion_nclt.pth\"\n",
    "\n",
    "print(inference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIPT finetune\n",
    "\n",
    "all_reg_recalls_aruco = []\n",
    "all_mean_reg_rotation_errors_aruco = []\n",
    "all_mean_reg_translation_errors_aruco = []\n",
    "all_median_reg_rotation_errors_aruco = []\n",
    "all_median_reg_translation_errors_aruco = []\n",
    "all_times_aruco = []\n",
    "RECALL_THRESHOLD = 25.0\n",
    "\n",
    "PR_MODEL_CONFIG_PATH = \"../../configs/model/place_recognition/multi-image_lidar_late-fusion.yaml\"\n",
    "PR_WEIGHTS_PATH = \"../../weights/place_recognition/multi-image_lidar_late-fusion_itlp-finetune.pth\"\n",
    "\n",
    "print(inference())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
