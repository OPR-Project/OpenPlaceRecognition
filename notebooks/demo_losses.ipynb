{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses subpackage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `opr.losses` subpackage contains ready-to-use loss functions implemented in PyTorch, featuring a common interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example - Batch Hard Triplet Margin Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n",
      "\u001b[32m2025-03-19 16:37:43.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mopr.models.place_recognition.pointmamba\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[33m\u001b[1mThe 'pointmamba' package is not installed. Please install it manually if neccessary.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from opr.models.place_recognition import MinkLoc3D\n",
    "from opr.datasets import OxfordDataset\n",
    "from opr.samplers import BatchSampler\n",
    "from opr.losses import BatchHardTripletMarginLoss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data source\n",
    "\n",
    "In this example, we use a pre-processed version of the Oxford RobotCar dataset.\n",
    "We use the same subsample of tracks and preprocessed point clouds as described in the \n",
    "[PointNetVLAD paper](https://openaccess.thecvf.com/content_cvpr_2018/html/Uy_PointNetVLAD_Deep_Point_CVPR_2018_paper.html).\n",
    "Additionally, we created the files \"train.csv\", \"val.csv\", and \"test.csv.\"\n",
    "\n",
    "You can download our version of the dataset via the following link:\n",
    "\n",
    "- [Kaggle](https://www.kaggle.com/datasets/creatorofuniverses/oxfordrobotcar-iprofi-hack-23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/core/validation.py:87: UserWarning: This augmenter is very slow. Try to use ``ElasticTransform`` instead, which is at least 10x faster.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/docker_opr/OpenPlaceRecognition/src/opr/datasets/augmentations.py:65: UserWarning: Argument(s) 'always_apply' are not valid for transform ColorJitter\n",
      "  A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, always_apply=True),\n",
      "/home/docker_opr/OpenPlaceRecognition/src/opr/datasets/augmentations.py:66: UserWarning: Argument(s) 'max_width, max_height, min_width, min_height, max_holes' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_width=96, max_height=66, min_width=32, min_height=22, max_holes=1, p=0.5),\n",
      "/home/docker_opr/OpenPlaceRecognition/src/opr/datasets/augmentations.py:180: UserWarning: Argument(s) 'max_width, max_height, min_width, min_height, max_holes' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(\n",
      "/home/docker_opr/OpenPlaceRecognition/src/opr/datasets/augmentations.py:183: UserWarning: Argument(s) 'max_width, max_height, min_width, min_height, max_holes' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(\n",
      "/home/docker_opr/OpenPlaceRecognition/src/opr/datasets/augmentations.py:186: UserWarning: Argument(s) 'unit_size_min, unit_size_max' are not valid for transform GridDropout\n",
      "  A.GridDropout(ratio=0.05, unit_size_min=4, unit_size_max=30, p=0.5),\n"
     ]
    }
   ],
   "source": [
    "dataset = OxfordDataset(\n",
    "    dataset_root=\"/home/docker_opr/Datasets/OpenPlaceRecognition/pnvlad_oxford_robotcar\",\n",
    "    subset=\"train\",\n",
    "    data_to_load=[\"pointcloud_lidar\"],\n",
    ")\n",
    "\n",
    "sampler = BatchSampler(\n",
    "    dataset=dataset,\n",
    "    batch_size=32,\n",
    "    positives_per_group=4\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_sampler=sampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=dataset.collate_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['idxs', 'utms', 'pointclouds_lidar_coords', 'pointclouds_lidar_feats'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch = next(iter(dataloader))\n",
    "sample_batch = {k: v.to(\"cuda\") for k, v in sample_batch.items()}\n",
    "sample_batch.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MinkLoc3D()\n",
    "model = model.to(\"cuda\")\n",
    "model.train();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['final_descriptor'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(sample_batch)\n",
    "output.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = BatchHardTripletMarginLoss(margin=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = sample_batch[\"idxs\"].cpu()\n",
    "positives_mask = dataset.positives_mask[idxs][:, idxs]\n",
    "negatives_mask = dataset.negatives_mask[idxs][:, idxs]\n",
    "\n",
    "loss, stats = loss_fn(output[\"final_descriptor\"], positives_mask, negatives_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.7753, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 5.775259017944336,\n",
       " 'avg_embedding_norm': 22.763263702392578,\n",
       " 'num_triplets': 32,\n",
       " 'num_non_zero_triplets': 32.0,\n",
       " 'non_zero_rate': 1.0,\n",
       " 'max_pos_pair_dist': 19.81702995300293,\n",
       " 'max_neg_pair_dist': 8.448206901550293,\n",
       " 'mean_pos_pair_dist': 8.219305992126465,\n",
       " 'mean_neg_pair_dist': 2.654839038848877,\n",
       " 'min_pos_pair_dist': 1.5070229768753052,\n",
       " 'min_neg_pair_dist': 1.222188115119934}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
