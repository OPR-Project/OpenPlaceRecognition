{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тест модуля восстановления глубины"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импортирование общих библиотек и OPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/kirill/TopoSLAM/OpenPlaceRecognition/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from scipy.spatial.transform import Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opr.pipelines.depth_estimation import DepthEstimationPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание нейросети восстановления глубины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/kirill/AdelaiDepth/LeReS/Minist_Test')\n",
    "from lib.multi_depth_model_woauxi import RelDepthModel\n",
    "from lib.net_tools import load_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(a):\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Configs for LeReS')\n",
    "    parser.add_argument('--load_ckpt', default='./res50.pth', help='Checkpoint path to load')\n",
    "    parser.add_argument('--backbone', default='resnext101', help='Checkpoint path to load')\n",
    "\n",
    "    args = parser.parse_args(a)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "arguments = \"--load_ckpt /home/kirill/AdelaiDepth/weights/res50.pth \\\n",
    "            --backbone resnet50\".split()\n",
    "args = parse_args(arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint /home/kirill/AdelaiDepth/weights/res50.pth\n"
     ]
    }
   ],
   "source": [
    "rel_depth_model = RelDepthModel(backbone='resnet50').cuda()\n",
    "load_ckpt(args, rel_depth_model, None, None)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch_tensorrt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from polygraphy.backend.trt import (\n",
    "    Calibrator,\n",
    "    TrtRunner,\n",
    "    CreateConfig,\n",
    "    engine_from_network,\n",
    "    engine_from_bytes,\n",
    "    engine_bytes_from_network,\n",
    "    network_from_onnx_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "type(rel_depth_model.depth_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "input_names = ['input']\n",
    "output_names = ['output']\n",
    "dummy_input = (torch.randn(1, 3, 480, 640, device='cuda'))\n",
    "torch.onnx.export(rel_depth_model.depth_model,\n",
    "            dummy_input,\n",
    "            \"adelaidepth_res50.onnx\",\n",
    "            verbose=True,\n",
    "            opset_version=13,\n",
    "            input_names=input_names,\n",
    "            output_names=output_names,\n",
    "            dynamic_axes={'input' : {0 : 'batch_size'},\n",
    "                          'output' : {0 : 'batch_size'}},\n",
    "            export_params=True,\n",
    "            do_constant_folding=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "debug = True\n",
    "# Workspace size for TensorRT\n",
    "workspace_size = 20 << 30\n",
    "# Maximum number of TRT Engines\n",
    "# (Lower value allows more graph segmentation)\n",
    "min_block_size = 7\n",
    "# Operations to Run in Torch, regardless of converter support\n",
    "torch_executed_ops = {}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "enabled_precisions = {torch.float32}\n",
    "trt_model = torch_tensorrt.compile(\n",
    "                            rel_depth_model.depth_model,\n",
    "                            ir=\"default\",\n",
    "                            inputs=['input'],\n",
    "                            enabled_precisions=enabled_precisions,\n",
    "                            debug=debug,\n",
    "                            workspace_size=workspace_size,\n",
    "                            min_block_size=min_block_size,\n",
    "                            torch_executed_ops=torch_executed_ops,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание трансформации между лидаром и камерой (данные из росбэга с робота Husky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_matrix = {'f': 683.6, 'cx': 615.1, 'cy': 345.3}\n",
    "rotation = [-0.498, 0.498, -0.495, 0.510]\n",
    "R = Rotation.from_quat(rotation).as_matrix()\n",
    "#R = np.linalg.inv(R)\n",
    "translation = np.array([[0.061], [0.049], [-0.131]])\n",
    "tf_matrix = np.concatenate([R, translation], axis=1)\n",
    "tf_matrix = np.concatenate([tf_matrix, np.array([[0, 0, 0, 1]])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01505794, -0.99977525, -0.01492309,  0.        ],\n",
       "       [ 0.00888194,  0.01505794, -0.99984717,  0.        ],\n",
       "       [ 0.99984717,  0.01492309,  0.00910668,  0.        ],\n",
       "       [ 0.061     ,  0.049     , -0.131     ,  1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Инициализация модуля восстановления глубины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = DepthEstimationPipeline(rel_depth_model)\n",
    "de.set_camera_matrix(camera_matrix)\n",
    "de.set_lidar_to_camera_transform(tf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Взятие тестового изображения и лидарного облака из датасета ITLP-Campus (сменить пути на актуальные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts = 1698265170740415257640960\n",
    "ts = 1698265251815700618543104\n",
    "test_img_file = '/home/kirill/TopoSLAM/OpenPlaceRecognition/data/floor5_processed/front_cam/{}.png'.format(ts)\n",
    "#ts_lidar = 1698265170777994342432768\n",
    "ts_lidar = 1698265251843991031250944\n",
    "test_cloud_file = '/home/kirill/TopoSLAM/OpenPlaceRecognition/data/floor5_processed/lidar/{}.bin'.format(ts_lidar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts = 1698265170740415257640960\n",
    "ts = 1326034709996300\n",
    "test_img_file = '/home/kirill/TopoSLAM/OpenPlaceRecognition/data/nclt_images/{}.png'.format(ts)\n",
    "#ts_lidar = 1698265170777994342432768\n",
    "test_cloud_file = '/home/kirill/TopoSLAM/OpenPlaceRecognition/data/nclt_images/{}.bin'.format(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1952734/1715114238.py:3: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  test_cloud = np.fromfile(test_cloud_file, sep=',').reshape((-1, 4))[:, :3]\n"
     ]
    }
   ],
   "source": [
    "test_img = imread(test_img_file)\n",
    "#test_img = resize(test_img, (480, 640))\n",
    "test_cloud = np.fromfile(test_cloud_file, sep=',').reshape((-1, 4))[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'NCLTProjector' from 'opr.datasets.projection' (/home/kirill/TopoSLAM/OpenPlaceRecognition/src/opr/datasets/projection.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NCLTProjector\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'NCLTProjector' from 'opr.datasets.projection' (/home/kirill/TopoSLAM/OpenPlaceRecognition/src/opr/datasets/projection.py)"
     ]
    }
   ],
   "source": [
    "from opr.datasets.projection import NCLTProjector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запуск восстановления глубины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth, rmse, rel = de.get_depth_with_lidar(test_img, test_cloud[:, :3])\n",
    "print('RMSE:', rmse)\n",
    "print('REL error:', rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth)\n",
    "plt.colorbar(shrink=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание облака точек по восстановленной глубине методом обратной проекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = depth.shape\n",
    "def get_point_cloud_from_depth(depth, f, cx, cy):\n",
    "    print(depth.shape, f, cx, cy)\n",
    "    i = np.tile(np.arange(h), w).reshape((w, h)).T\n",
    "    j = np.tile(np.arange(w), h).reshape((h, w))\n",
    "    z = depth.ravel()\n",
    "    x = (j.ravel() - cx) / f * z\n",
    "    y = (i.ravel() - cy) / f * z\n",
    "    pcd = np.zeros((x.shape[0], 3))\n",
    "    pcd[:, 0] = x\n",
    "    pcd[:, 1] = y\n",
    "    pcd[:, 2] = z\n",
    "    return pcd\n",
    "\n",
    "pcd = get_point_cloud_from_depth(depth, camera_matrix['f'], camera_matrix['cx'], camera_matrix['cy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.scatter(pcd[:, 2], -pcd[:, 0], s=5, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравнение восстановленного и лидарного облака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.xlim((-8, 8))\n",
    "plt.ylim((-5, 11))\n",
    "plt.scatter(test_cloud[:, 0], test_cloud[:, 1], s=5, alpha=0.1)\n",
    "plt.scatter(pcd[::17, 2] * 1.15, -pcd[::17, 0] * 1.15, color='orange', s=5, alpha=0.1)\n",
    "plt.savefig('pointcloud_from_nn_depth.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_mink",
   "language": "python",
   "name": "py3_mink"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
